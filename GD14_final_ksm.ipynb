{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "historical-publication",
   "metadata": {},
   "source": [
    "# NLP Going Deeper 14 : BERT pretrained model 제작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-amsterdam",
   "metadata": {},
   "source": [
    "이번 노드에서는 일반적인 10M 정도의 작은 파라미터 사이즈의 BERT 모델을 만들어, 수백 MB 수준의 코퍼스 기반으로 pretrain 을 진행해 보도록 하겠습니다. 하지만 진행되는 과정은 정식 BERT와 동일할 테니 이를 토대로 pretrained model이 어떻게 만들어지는지를 경험할 것입니다.\n",
    "\n",
    "모델을 만들고 학습시키는 것 이상으로 코퍼스 데이터를 가공해서 학습시켜야 할 task에 적합한 형태의 데이터셋으로 만들어가는 것이 큰 비중을 차지한다는 것을 알게 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-setup",
   "metadata": {},
   "source": [
    "## 작업 환경 구성"
   ]
  },
  {
   "attachments": {
    "001.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "nuclear-relative",
   "metadata": {},
   "source": [
    "![001.PNG](attachment:001.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-drink",
   "metadata": {},
   "source": [
    "## Tokenizer 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-encounter",
   "metadata": {},
   "source": [
    "BERT등의 pretrained model이 나오게 되었을 즈음, 자연어 처리 분야의 또 다른 중요한 흐름 중 하나는 BPE 등의 subword 기반의 토크나이징 기법이 주요한 방법론으로 굳어졌다는 점입니다. GPT의 BPE, BERT의 WordPiece 모델 등의 성공이 더욱 사람들에게 subword 기반의 토크나이저에 대한 확신을 주었습니다.\n",
    "\n",
    "이번 노드에서는 SentencePiece 기반의 토크나이저를 준비하는 것으로 BERT pretrain 과정을 시작하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "renewable-baker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# tf version 및 gpu 확인\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-checklist",
   "metadata": {},
   "source": [
    "준비해 둔 한글 나무위키 코퍼스로부터 **8000의 vocab_size를 갖는 sentencepiece 모델을 생성**해 보겠습니다.\n",
    "\n",
    "BERT에 사용되는 [MASK], [SEP], [CLS] 등의 주요 특수문자가 vocab에 포함되어야 함을 유의하는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "altered-commerce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 size의 모델 생성 절차 완료!\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "prefix = 'ko_8000'\n",
    "vocab_size = 8000\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus_file} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰\n",
    "\n",
    "print(\"8000 size의 모델 생성 절차 완료!\")   # 완료메시지가 출력될 때까지 아무 출력내용이 없더라도 기다려 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-respondent",
   "metadata": {},
   "source": [
    "저는 심볼릭 링크를 걸어주는 방법을 사용하도록 하겠습니다."
   ]
  },
  {
   "attachments": {
    "002.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "prime-documentary",
   "metadata": {},
   "source": [
    "![002.PNG](attachment:002.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "third-tanzania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/data'\n",
    "model_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/models'\n",
    "\n",
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_32000.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-carter",
   "metadata": {},
   "source": [
    "어떤 토큰이 만들어졌고, 토크나이징 결과가 어떻게 나오는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quiet-corruption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁1', '▁이', '으로', '에서', '▁있', '▁2', '▁그', '▁대', '▁사', '이다', '었다', '▁지', '▁수', '▁19', '▁가', '▁시', '▁20', '▁기', '▁전', '▁아', '▁하', '▁있다', '▁다', '▁제', '했다', '하였', '▁일', '▁한', '▁중', '▁정']\n"
     ]
    }
   ],
   "source": [
    "## 어떤 토큰이 만들어졌는지를 확인하는 코드입니다.\n",
    "# 특수 token 7개를 제외한 나머지 tokens에 대하여\n",
    "vocab_list = []\n",
    "for id in range(7, len(vocab)):\n",
    "    if not vocab.is_unknown(id):\n",
    "        vocab_list.append(vocab.id_to_piece(id))\n",
    "print(vocab_list[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prompt-graphics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁많이', '▁어두운', '▁밤', '이', '▁끝날', '▁것', '▁같', '지', '▁않', '던', '▁시간', '▁다', '들', '▁쉽게', '▁내', '뱉', '는', '▁말', '▁그냥', '▁지나면', '▁추억', '이야', '[SEP]', '▁아무', '▁말', '▁없이', '▁난', '▁그냥', '▁네', '▁뒤에', '▁서', '▁있을', '게', '▁언제나', '▁모든', '▁순간', '순', '간에', '▁네', '▁편이', '▁되어', '▁줄', '▁거', '야', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "## 토크나이징 결과가 어떻게 나오는지 확인하는 코드입니다.\n",
    "## string 예시문은 트라이비의 'GOT YOUR BACK'이라는 노래 가사의 일부입니다!\n",
    "# [CLS], tokens a, [SEP], tokens b, [SEP] 형태의 token 생성\n",
    "string_a = \"많이 어두운 밤이 끝날 것 같지 않던 시간 다들 쉽게 내뱉는 말 그냥 지나면 추억이야\"\n",
    "string_b = \"아무 말 없이 난 그냥 네 뒤에 서 있을게 언제나 모든 순간순간에 네 편이 되어 줄 거야\"\n",
    "tokens_org = [\"[CLS]\"] + vocab.encode_as_pieces(string_a) + [\"[SEP]\"] + vocab.encode_as_pieces(string_b) + [\"[SEP]\"]\n",
    "print(tokens_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-dallas",
   "metadata": {},
   "source": [
    "여기까지 SentencePiece 모델을 이용해 간단한 BERT의 Masked Language Model 학습용 데이터를 하나 생성하는 과정을 살펴보았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-washer",
   "metadata": {},
   "source": [
    "## 데이터 전처리 : MASK 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-williams",
   "metadata": {},
   "source": [
    "BERT의 Masked Language Model은 GPT의 Next Token Prediction 태스크처럼 '다음에 이어질 단어는?' 을 맞추는 게 아니라 '마스킹된 다음 빈칸에 알맞은 단어는?' 문제를 푸는 형식으로 구성됩니다. 이런 빈칸은 **전체 토큰의 15%** 정도가 적당하다고 합니다.\n",
    "\n",
    "이전 스텝의 Masked LM 데이터셋 예시로 살펴보면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "uniform-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁많이', '▁어두운', '▁밤', '이', '▁끝날', '▁것', '▁같', '지', '▁않', '던', '▁시간', '▁다', '들', '▁쉽게', '▁내', '뱉', '는', '▁말', '▁그냥', '▁지나면', '▁추억', '이야', '[SEP]', '▁아무', '▁말', '▁없이', '▁난', '▁그냥', '▁네', '▁뒤에', '▁서', '▁있을', '게', '▁언제나', '▁모든', '▁순간', '순', '간에', '▁네', '▁편이', '▁되어', '▁줄', '▁거', '야', '[SEP]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokens_org)\n",
    "\n",
    "# 전체 token의 15% mask\n",
    "mask_cnt = int((len(tokens_org) - 3) * 0.15)\n",
    "mask_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-optimum",
   "metadata": {},
   "source": [
    "한편, Masked LM 태스크를 구성할 땐 띄어쓰기 단위로 한꺼번에 마스킹해 주는 것이 좋습니다. 다음과 같이 처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lucky-student",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] ['▁많이']\n",
      "[2] ['▁어두운']\n",
      "[3, 4] ['▁밤', '이']\n",
      "[5] ['▁끝날']\n",
      "[6] ['▁것']\n",
      "[7, 8] ['▁같', '지']\n",
      "[9, 10] ['▁않', '던']\n",
      "[11] ['▁시간']\n",
      "[12, 13] ['▁다', '들']\n",
      "[14] ['▁쉽게']\n",
      "[15, 16, 17] ['▁내', '뱉', '는']\n",
      "[18] ['▁말']\n",
      "[19] ['▁그냥']\n",
      "[20] ['▁지나면']\n",
      "[21, 22] ['▁추억', '이야']\n",
      "[24] ['▁아무']\n",
      "[25] ['▁말']\n",
      "[26] ['▁없이']\n",
      "[27] ['▁난']\n",
      "[28] ['▁그냥']\n",
      "[29] ['▁네']\n",
      "[30] ['▁뒤에']\n",
      "[31] ['▁서']\n",
      "[32, 33] ['▁있을', '게']\n",
      "[34] ['▁언제나']\n",
      "[35] ['▁모든']\n",
      "[36, 37, 38] ['▁순간', '순', '간에']\n",
      "[39] ['▁네']\n",
      "[40] ['▁편이']\n",
      "[41] ['▁되어']\n",
      "[42] ['▁줄']\n",
      "[43, 44] ['▁거', '야']\n"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기 단위로 mask 하기 위해서 index 분할\n",
    "cand_idx = []  # word 단위의 index array\n",
    "for (i, token) in enumerate(tokens_org):\n",
    "    if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "        continue\n",
    "    if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
    "        cand_idx[-1].append(i)\n",
    "    else:\n",
    "        cand_idx.append([i])\n",
    "\n",
    "# 결과확인\n",
    "for cand in cand_idx:\n",
    "    print(cand, [tokens_org[i] for i in cand])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-plenty",
   "metadata": {},
   "source": [
    "한편, 랜덤한 마스킹을 위해서 순서를 섞는 작업을 걸어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cutting-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(cand_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aboriginal-arrangement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12, 13],\n",
       " [21, 22],\n",
       " [6],\n",
       " [34],\n",
       " [9, 10],\n",
       " [25],\n",
       " [7, 8],\n",
       " [24],\n",
       " [39],\n",
       " [32, 33],\n",
       " [19],\n",
       " [20],\n",
       " [28],\n",
       " [14],\n",
       " [15, 16, 17],\n",
       " [29],\n",
       " [26],\n",
       " [36, 37, 38],\n",
       " [41],\n",
       " [11],\n",
       " [18],\n",
       " [42],\n",
       " [43, 44],\n",
       " [31],\n",
       " [30],\n",
       " [2],\n",
       " [27],\n",
       " [35],\n",
       " [3, 4],\n",
       " [1],\n",
       " [5],\n",
       " [40]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-regression",
   "metadata": {},
   "source": [
    "개선된 Masking 로직을 다음과 같이 구현할 수 있습니다. 마스킹된 결과를 이전과 비교해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "healthy-ministry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_org\n",
      "['[CLS]', '▁많이', '▁어두운', '▁밤', '이', '▁끝날', '▁것', '▁같', '지', '▁않', '던', '▁시간', '▁다', '들', '▁쉽게', '▁내', '뱉', '는', '▁말', '▁그냥', '▁지나면', '▁추억', '이야', '[SEP]', '▁아무', '▁말', '▁없이', '▁난', '▁그냥', '▁네', '▁뒤에', '▁서', '▁있을', '게', '▁언제나', '▁모든', '▁순간', '순', '간에', '▁네', '▁편이', '▁되어', '▁줄', '▁거', '야', '[SEP]'] \n",
      "\n",
      "tokens\n",
      "['[CLS]', '▁많이', '▁어두운', '▁밤', '이', '▁끝날', '[MASK]', '▁같', '지', '▁않', '던', '▁시간', '[MASK]', '[MASK]', '▁쉽게', '▁내', '뱉', '는', '▁말', '▁그냥', '▁지나면', '카와', '▁화재로', '[SEP]', '▁아무', '▁말', '▁없이', '▁난', '▁그냥', '▁네', '▁뒤에', '▁서', '▁있을', '게', '[MASK]', '▁모든', '▁순간', '순', '간에', '▁네', '▁편이', '▁되어', '▁줄', '▁거', '야', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# tokens가 mask되므로 재 실행을 위해서 넣어줌 (테스트용)\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "mask_lms = []  # mask 된 값\n",
    "for index_set in cand_idx:\n",
    "    if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
    "          break\n",
    "    if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "          continue\n",
    "    dice = random.random()  # 0..1 사이의 확률 값\n",
    "\n",
    "    for index in index_set:\n",
    "        masked_token = None\n",
    "        if dice < 0.8:  # 80% replace with [MASK]\n",
    "            masked_token = \"[MASK]\"\n",
    "        elif dice < 0.9: # 10% keep original\n",
    "            masked_token = tokens[index]\n",
    "        else:  # 10% random word\n",
    "            masked_token = random.choice(vocab_list)\n",
    "        mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "        tokens[index] = masked_token\n",
    "\n",
    "print(\"tokens_org\")\n",
    "print(tokens_org, \"\\n\")\n",
    "print(\"tokens\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-barrel",
   "metadata": {},
   "source": [
    "Masked LM의 라벨 데이터도 아래와 같이 생성한 후 정리해 두기로 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "southwest-gauge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_idx   : [6, 12, 13, 21, 22, 34]\n",
      "mask_label : ['▁것', '▁다', '들', '▁추억', '이야', '▁언제나']\n"
     ]
    }
   ],
   "source": [
    "# 순서 정렬 및 mask_idx, mask_label 생성\n",
    "mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "print(\"mask_idx   :\", mask_idx)\n",
    "print(\"mask_label :\", mask_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "invisible-luxury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 6, 'label': '▁것'},\n",
       " {'index': 12, 'label': '▁다'},\n",
       " {'index': 13, 'label': '들'},\n",
       " {'index': 21, 'label': '▁추억'},\n",
       " {'index': 22, 'label': '이야'},\n",
       " {'index': 34, 'label': '▁언제나'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_lms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-orleans",
   "metadata": {},
   "source": [
    "### create_pretrain_mask() : Masked LM을 위한 코퍼스 생성 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fourth-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "    \"\"\"\n",
    "    마스크 생성\n",
    "    :param tokens: tokens\n",
    "    :param mask_cnt: mask 개수 (전체 tokens의 15%)\n",
    "    :param vocab_list: vocab list (random token 용)\n",
    "    :return tokens: mask된 tokens\n",
    "    :return mask_idx: mask된 token의 index\n",
    "    :return mask_label: mask된 token의 원래 값\n",
    "    \"\"\"\n",
    "    # 단어 단위로 mask 하기 위해서 index 분할\n",
    "    cand_idx = []  # word 단위의 index array\n",
    "    for (i, token) in enumerate(tokens):\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
    "            cand_idx[-1].append(i)\n",
    "        else:\n",
    "            cand_idx.append([i])\n",
    "    # random mask를 위해서 순서를 섞음\n",
    "    random.shuffle(cand_idx)\n",
    "\n",
    "    mask_lms = []  # mask 된 값\n",
    "    for index_set in cand_idx:\n",
    "        if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
    "            break\n",
    "        if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "            continue\n",
    "        dice = random.random()  # 0..1 사이의 확률 값\n",
    "        for index in index_set:\n",
    "            masked_token = None\n",
    "            if dice < 0.8:  # 80% replace with [MASK]\n",
    "                masked_token = \"[MASK]\"\n",
    "            elif dice < 0.9: # 10% keep original\n",
    "                masked_token = tokens[index]\n",
    "            else:  # 10% random word\n",
    "                masked_token = random.choice(vocab_list)\n",
    "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "            tokens[index] = masked_token\n",
    "    # mask_lms 정렬 후 mask_idx, mask_label 추출\n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]  # mask된 token의 index\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]  # mask된 token의 원래 값\n",
    "\n",
    "    return tokens, mask_idx, mask_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-buying",
   "metadata": {},
   "source": [
    "create_pretrain_mask() 수행 결과를 다시 한 번 확인해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abstract-sheep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens_org\n",
      "['[CLS]', '▁많이', '▁어두운', '▁밤', '이', '▁끝날', '▁것', '▁같', '지', '▁않', '던', '▁시간', '▁다', '들', '▁쉽게', '▁내', '뱉', '는', '▁말', '▁그냥', '▁지나면', '▁추억', '이야', '[SEP]', '▁아무', '▁말', '▁없이', '▁난', '▁그냥', '▁네', '▁뒤에', '▁서', '▁있을', '게', '▁언제나', '▁모든', '▁순간', '순', '간에', '▁네', '▁편이', '▁되어', '▁줄', '▁거', '야', '[SEP]'] \n",
      "\n",
      "tokens\n",
      "['[CLS]', '▁많이', '[MASK]', '▁밤', '이', '[MASK]', '[MASK]', '▁같', '지', '▁않', '던', '▁시간', '▁다', '들', '▁쉽게', '▁내', '뱉', '는', '▁말', '▁그냥', '[MASK]', '▁추억', '이야', '[SEP]', '▁아무', '▁말', '▁없이', '▁난', '▁그냥', '▁네', '▁뒤에', '렸기', '▁있을', '게', '▁언제나', '[MASK]', '▁순간', '순', '간에', '▁네', '▁편이', '▁되어', '▁줄', '▁거', '야', '[SEP]'] \n",
      "\n",
      "mask_idx   : [2, 5, 6, 20, 31, 35]\n",
      "mask_label : ['▁어두운', '▁끝날', '▁것', '▁지나면', '▁서', '▁모든']\n"
     ]
    }
   ],
   "source": [
    "# tokens가 mask되므로 재 실행을 위해서 넣어줌 (테스트용)\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "tokens, mask_idx, mask_label = create_pretrain_mask(tokens, mask_cnt, vocab_list)\n",
    "\n",
    "print(\"tokens_org\")\n",
    "print(tokens_org, \"\\n\")\n",
    "print(\"tokens\")\n",
    "print(tokens, \"\\n\")\n",
    "\n",
    "print(\"mask_idx   :\", mask_idx)\n",
    "print(\"mask_label :\", mask_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-france",
   "metadata": {},
   "source": [
    "## 데이터 전처리 : NSP Pair 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-temple",
   "metadata": {},
   "source": [
    "BERT의 pretrain task로 **Next Sentence Prediction(NSP)** 이 있습니다. 문장 2개를 붙여 놓고 두 문장이 이어지는 것인지 아닌지 문장 호응관계를 맞출 수 있게 하는 것입니다.\n",
    "\n",
    "예시문은 아래 링크의 글의 일부분을 Copy 및 편집한 것임을 밝힙니다.\n",
    "\n",
    "**링크 : https://www.brainmedia.co.kr/MediaContent/MediaContentView.aspx?MenuCd=BRAINTRAINING&contIdx=22088**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "going-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\"\"퇴근 후 각자의 공간에서 참석하는 화상 모임의\n",
    "주된 활동은 국학기공 수련이다. 몸과 마음의 고단함을\n",
    "수련으로 비우고 회복하는 소중한 시간이다.\n",
    "간단한 동작을 하면서 호흡과 어우러지는 몸의 움직임을\n",
    "느끼며 몸과 마음을 지금 이곳에 머물도록 하는\n",
    "시공간적 집중상태로 한결 편안한 분위기가 된다.\n",
    "어느 정도 호흡이 정리되면 머리가 맑아지고 몸도 가벼워진\n",
    "상태에서 몇몇 선생님들의 국학기공 교육 활동 사례를\n",
    "공유하는 시간을 갖는다.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "protecting-velvet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁퇴', '근', '▁후', '▁각자의', '▁공간에서', '▁참석', '하는', '▁화', '상', '▁모임', '의'],\n",
       " ['▁주된',\n",
       "  '▁활동은',\n",
       "  '▁국',\n",
       "  '학',\n",
       "  '기',\n",
       "  '공',\n",
       "  '▁수련',\n",
       "  '이다',\n",
       "  '.',\n",
       "  '▁몸',\n",
       "  '과',\n",
       "  '▁마음의',\n",
       "  '▁고',\n",
       "  '단',\n",
       "  '함을'],\n",
       " ['▁수련', '으로', '▁비', '우고', '▁회복', '하는', '▁소', '중한', '▁시간', '이다', '.']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 줄 단위로 tokenize\n",
    "doc = [vocab.encode_as_pieces(line) for line in string.split(\"\\n\")]\n",
    "doc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-houston",
   "metadata": {},
   "source": [
    "우선 원문에서 이어진 두 문장씩 짝지어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "specific-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이\n",
    "n_test_seq = 64\n",
    "# 최소 길이\n",
    "min_seq = 8\n",
    "# [CLS], tokens_a, [SEB], tokens_b, [SEP]\n",
    "max_seq = n_test_seq - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "forbidden-commitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_chunk: 6 69 [['▁퇴', '근', '▁후', '▁각자의', '▁공간에서', '▁참석', '하는', '▁화', '상', '▁모임', '의'], ['▁주된', '▁활동은', '▁국', '학', '기', '공', '▁수련', '이다', '.', '▁몸', '과', '▁마음의', '▁고', '단', '함을'], ['▁수련', '으로', '▁비', '우고', '▁회복', '하는', '▁소', '중한', '▁시간', '이다', '.'], ['▁간단한', '▁동작을', '▁하면서', '▁호흡', '과', '▁어우러', '지는', '▁몸의', '▁움직임을'], ['▁느끼', '며', '▁몸', '과', '▁마음을', '▁지금', '▁이곳에', '▁머물', '도록', '▁하는'], ['▁시', '공간', '적', '▁집중', '상태', '로', '▁한', '결', '▁편안', '한', '▁분위기가', '▁된다', '.']]\n",
      "tokens_a: 46 ['▁퇴', '근', '▁후', '▁각자의', '▁공간에서', '▁참석', '하는', '▁화', '상', '▁모임', '의', '▁주된', '▁활동은', '▁국', '학', '기', '공', '▁수련', '이다', '.', '▁몸', '과', '▁마음의', '▁고', '단', '함을', '▁수련', '으로', '▁비', '우고', '▁회복', '하는', '▁소', '중한', '▁시간', '이다', '.', '▁간단한', '▁동작을', '▁하면서', '▁호흡', '과', '▁어우러', '지는', '▁몸의', '▁움직임을']\n",
      "tokens_b: 23 ['▁느끼', '며', '▁몸', '과', '▁마음을', '▁지금', '▁이곳에', '▁머물', '도록', '▁하는', '▁시', '공간', '적', '▁집중', '상태', '로', '▁한', '결', '▁편안', '한', '▁분위기가', '▁된다', '.']\n",
      "\n",
      "current_chunk: 3 30 [['▁어느', '▁정도', '▁호흡', '이', '▁정리', '되면', '▁머리가', '▁맑', '아', '지고', '▁몸', '도', '▁가벼', '워', '진'], ['▁상태에서', '▁몇몇', '▁선생님', '들의', '▁국', '학', '기', '공', '▁교육', '▁활동', '▁사례를'], ['▁공유하는', '▁시간을', '▁갖는다', '.']]\n",
      "tokens_a: 26 ['▁어느', '▁정도', '▁호흡', '이', '▁정리', '되면', '▁머리가', '▁맑', '아', '지고', '▁몸', '도', '▁가벼', '워', '진', '▁상태에서', '▁몇몇', '▁선생님', '들의', '▁국', '학', '기', '공', '▁교육', '▁활동', '▁사례를']\n",
      "tokens_b: 4 ['▁공유하는', '▁시간을', '▁갖는다', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_chunk = []  # line 단위 tokens\n",
    "current_length = 0\n",
    "for i in range(len(doc)):  # doc 전체를 loop\n",
    "    current_chunk.append(doc[i])  # line 단위로 추가\n",
    "    current_length += len(doc[i])  # current_chunk의 token 수\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # 마지막 줄 이거나 길이가 max_seq 이상 인 경우\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "        #######################################\n",
    "        # token a\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "        # token b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "          \n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        #######################################\n",
    "        print()\n",
    "\n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-hollywood",
   "metadata": {},
   "source": [
    "짝지은 두 문장을 그대로 두면 NSP task의 true label 케이스가 되고, 둘의 순서를 뒤바꾸면 false label 케이스가 될 것입니다.\n",
    "\n",
    "두 문장의 최대 길이를 유지하도록 trim을 적용한 후 50%의 확률로 T/F 케이스를 생성해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "grateful-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    \"\"\"\n",
    "    tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
    "    :param tokens_a: tokens A\n",
    "    :param tokens_b: tokens B\n",
    "    :param max_seq: 두 tokens 길이의 최대 값\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "blind-discretion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_chunk: 6 69 [['▁퇴', '근', '▁후', '▁각자의', '▁공간에서', '▁참석', '하는', '▁화', '상', '▁모임', '의'], ['▁주된', '▁활동은', '▁국', '학', '기', '공', '▁수련', '이다', '.', '▁몸', '과', '▁마음의', '▁고', '단', '함을'], ['▁수련', '으로', '▁비', '우고', '▁회복', '하는', '▁소', '중한', '▁시간', '이다', '.'], ['▁간단한', '▁동작을', '▁하면서', '▁호흡', '과', '▁어우러', '지는', '▁몸의', '▁움직임을'], ['▁느끼', '며', '▁몸', '과', '▁마음을', '▁지금', '▁이곳에', '▁머물', '도록', '▁하는'], ['▁시', '공간', '적', '▁집중', '상태', '로', '▁한', '결', '▁편안', '한', '▁분위기가', '▁된다', '.']]\n",
      "is_next: 0\n",
      "tokens_a: 50 ['.', '▁몸', '과', '▁마음의', '▁고', '단', '함을', '▁수련', '으로', '▁비', '우고', '▁회복', '하는', '▁소', '중한', '▁시간', '이다', '.', '▁간단한', '▁동작을', '▁하면서', '▁호흡', '과', '▁어우러', '지는', '▁몸의', '▁움직임을', '▁느끼', '며', '▁몸', '과', '▁마음을', '▁지금', '▁이곳에', '▁머물', '도록', '▁하는', '▁시', '공간', '적', '▁집중', '상태', '로', '▁한', '결', '▁편안', '한', '▁분위기가', '▁된다', '.']\n",
      "tokens_b: 11 ['▁퇴', '근', '▁후', '▁각자의', '▁공간에서', '▁참석', '하는', '▁화', '상', '▁모임', '의']\n",
      "\n",
      "current_chunk: 3 30 [['▁어느', '▁정도', '▁호흡', '이', '▁정리', '되면', '▁머리가', '▁맑', '아', '지고', '▁몸', '도', '▁가벼', '워', '진'], ['▁상태에서', '▁몇몇', '▁선생님', '들의', '▁국', '학', '기', '공', '▁교육', '▁활동', '▁사례를'], ['▁공유하는', '▁시간을', '▁갖는다', '.']]\n",
      "is_next: 0\n",
      "tokens_a: 15 ['▁상태에서', '▁몇몇', '▁선생님', '들의', '▁국', '학', '기', '공', '▁교육', '▁활동', '▁사례를', '▁공유하는', '▁시간을', '▁갖는다', '.']\n",
      "tokens_b: 15 ['▁어느', '▁정도', '▁호흡', '이', '▁정리', '되면', '▁머리가', '▁맑', '아', '지고', '▁몸', '도', '▁가벼', '워', '진']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_chunk = []  # line 단위 tokens\n",
    "current_length = 0\n",
    "for i in range(len(doc)):  # doc 전체를 loop\n",
    "    current_chunk.append(doc[i])  # line 단위로 추가\n",
    "    current_length += len(doc[i])  # current_chunk의 token 수\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # 마지막 줄 이거나 길이가 max_seq 이상 인 경우\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "        # token a\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "        # token b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "\n",
    "        #######################################\n",
    "        if random.random() < 0.5:  # 50% 확률로 swap\n",
    "            is_next = 0\n",
    "            tokens_t = tokens_a\n",
    "            tokens_a = tokens_b\n",
    "            tokens_b = tokens_t\n",
    "        else:\n",
    "            is_next = 1\n",
    "        # max_seq 보다 큰 경우 길이 조절\n",
    "        trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "        assert 0 < len(tokens_a)\n",
    "        assert 0 < len(tokens_b)\n",
    "\n",
    "        print(\"is_next:\", is_next)\n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        #######################################\n",
    "        print()\n",
    "\n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-phenomenon",
   "metadata": {},
   "source": [
    "이제 두 문장 사이에 segment 처리를 해 주도록 합니다. 첫 번째 문장의 segment는 모두 0으로, 두 번째 문장은 1로 채워준 후 둘 사이에 구분자인 [SEP] 등을 넣어주는 것으로 마무리가 됩니다.\n",
    "\n",
    "이전 스텝의 create_pretrain_mask() 까지 함께 호출되어 Mask LM용 데이터셋과 NSP용 데이터셋이 결합된 하나의 데이터셋으로 완성될 것입니다.\n",
    "\n",
    "**참고로, BERT의 pretrain은 두 가지 task가 동시에 수행 가능합니다! 😉😉**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wooden-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_chunk: 6 69 [['▁퇴', '근', '▁후', '▁각자의', '▁공간에서', '▁참석', '하는', '▁화', '상', '▁모임', '의'], ['▁주된', '▁활동은', '▁국', '학', '기', '공', '▁수련', '이다', '.', '▁몸', '과', '▁마음의', '▁고', '단', '함을'], ['▁수련', '으로', '▁비', '우고', '▁회복', '하는', '▁소', '중한', '▁시간', '이다', '.'], ['▁간단한', '▁동작을', '▁하면서', '▁호흡', '과', '▁어우러', '지는', '▁몸의', '▁움직임을'], ['▁느끼', '며', '▁몸', '과', '▁마음을', '▁지금', '▁이곳에', '▁머물', '도록', '▁하는'], ['▁시', '공간', '적', '▁집중', '상태', '로', '▁한', '결', '▁편안', '한', '▁분위기가', '▁된다', '.']]\n",
      "is_next: 1\n",
      "tokens_a: 26 ['▁퇴', '근', '▁후', '▁각자의', '▁공간에서', '▁참석', '하는', '▁화', '상', '▁모임', '의', '▁주된', '▁활동은', '▁국', '학', '기', '공', '▁수련', '이다', '.', '▁몸', '과', '▁마음의', '▁고', '단', '함을']\n",
      "tokens_b: 35 ['▁수련', '으로', '▁비', '우고', '▁회복', '하는', '▁소', '중한', '▁시간', '이다', '.', '▁간단한', '▁동작을', '▁하면서', '▁호흡', '과', '▁어우러', '지는', '▁몸의', '▁움직임을', '▁느끼', '며', '▁몸', '과', '▁마음을', '▁지금', '▁이곳에', '▁머물', '도록', '▁하는', '▁시', '공간', '적', '▁집중', '상태']\n",
      "tokens: 64 ['[CLS]', '▁퇴', '근', '▁후', '▁각자의', '▁공간에서', '▁참석', '하는', '▁화', '상', '▁모임', '의', '▁주된', '▁활동은', '▁국', '학', '기', '공', '▁수련', '이다', '.', '▁몸', '과', '▁마음의', '▁고', '단', '함을', '[SEP]', '▁수련', '으로', '▁비', '우고', '▁회복', '하는', '▁소', '중한', '▁시간', '이다', '.', '▁간단한', '▁동작을', '▁하면서', '▁호흡', '과', '▁어우러', '지는', '▁몸의', '▁움직임을', '▁느끼', '며', '▁몸', '과', '▁마음을', '▁지금', '▁이곳에', '▁머물', '도록', '▁하는', '▁시', '공간', '적', '▁집중', '상태', '[SEP]']\n",
      "segment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "masked tokens: 64 ['[CLS]', '▁퇴', '근', '▁후', '▁각자의', '▁공간에서', '[MASK]', '[MASK]', '▁화', '상', '▁모임', '의', '▁주된', '▁활동은', '▁국', '학', '기', '공', '▁수련', '이다', '.', '[MASK]', '[MASK]', '▁마음의', '▁고', '단', '함을', '[SEP]', '▁수련', '으로', '▁비', '우고', '▁회복', '하는', '▁대만', '澗', '▁시간', '이다', '.', '▁간단한', '▁동작을', '[MASK]', '▁호흡', '과', '▁어우러', '지는', '▁몸의', '▁움직임을', '▁느끼', '며', '▁몸', '과', '▁마음을', '▁지금', '▁이곳에', '▁머물', '도록', '▁하는', '▁시', '공간', '적', '▁집중', '상태', '[SEP]']\n",
      "masked index: 9 [1, 2, 6, 7, 21, 22, 34, 35, 41]\n",
      "masked label: 6 ['▁어두운', '▁끝날', '▁것', '▁지나면', '▁서', '▁모든']\n",
      "\n",
      "current_chunk: 3 30 [['▁어느', '▁정도', '▁호흡', '이', '▁정리', '되면', '▁머리가', '▁맑', '아', '지고', '▁몸', '도', '▁가벼', '워', '진'], ['▁상태에서', '▁몇몇', '▁선생님', '들의', '▁국', '학', '기', '공', '▁교육', '▁활동', '▁사례를'], ['▁공유하는', '▁시간을', '▁갖는다', '.']]\n",
      "is_next: 1\n",
      "tokens_a: 26 ['▁어느', '▁정도', '▁호흡', '이', '▁정리', '되면', '▁머리가', '▁맑', '아', '지고', '▁몸', '도', '▁가벼', '워', '진', '▁상태에서', '▁몇몇', '▁선생님', '들의', '▁국', '학', '기', '공', '▁교육', '▁활동', '▁사례를']\n",
      "tokens_b: 4 ['▁공유하는', '▁시간을', '▁갖는다', '.']\n",
      "tokens: 33 ['[CLS]', '▁어느', '▁정도', '▁호흡', '이', '▁정리', '되면', '▁머리가', '▁맑', '아', '지고', '▁몸', '도', '▁가벼', '워', '진', '▁상태에서', '▁몇몇', '▁선생님', '들의', '▁국', '학', '기', '공', '▁교육', '▁활동', '▁사례를', '[SEP]', '▁공유하는', '▁시간을', '▁갖는다', '.', '[SEP]']\n",
      "segment: 33 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "masked tokens: 33 ['[CLS]', '▁어느', '▁정도', '▁호흡', '이', '▁정리', '되면', '▁머리가', '▁맑', '아', '지고', '▁몸', '도', '▁가벼', '워', '진', '▁상태에서', '[MASK]', '▁선생님', '들의', '▁국', '학', '기', '공', '▁교육', '▁활동', '▁사례를', '[SEP]', '[MASK]', '▁시간을', '▁갖는다', '.', '[SEP]']\n",
      "masked index: 4 [17, 18, 19, 28]\n",
      "masked label: 6 ['▁어두운', '▁끝날', '▁것', '▁지나면', '▁서', '▁모든']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instances = []\n",
    "current_chunk = []  # line 단위 tokens\n",
    "current_length = 0\n",
    "for i in range(len(doc)):  # doc 전체를 loop\n",
    "    current_chunk.append(doc[i])  # line 단위로 추가\n",
    "    current_length += len(doc[i])  # current_chunk의 token 수\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # 마지막 줄 이거나 길이가 max_seq 이상 인 경우\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "        # token a\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "        # token b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "\n",
    "        if random.random() < 0.5:  # 50% 확률로 swap\n",
    "            is_next = 0\n",
    "            tokens_t = tokens_a\n",
    "            tokens_a = tokens_b\n",
    "            tokens_b = tokens_t\n",
    "        else:\n",
    "            is_next = 1\n",
    "        # max_seq 보다 큰 경우 길이 조절\n",
    "        trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "        assert 0 < len(tokens_a)\n",
    "        assert 0 < len(tokens_b)\n",
    "\n",
    "        print(\"is_next:\", is_next)\n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        #################################################\n",
    "        # tokens & aegment 생성\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "        segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "        print(\"tokens:\", len(tokens), tokens)\n",
    "        print(\"segment:\", len(segment), segment)\n",
    "        # mask\n",
    "        tokens, mask_idx, mask_table = create_pretrain_mask(tokens, int((len(tokens) - 3) * 0.15), vocab_list)\n",
    "        print(\"masked tokens:\", len(tokens), tokens)\n",
    "        print(\"masked index:\", len(mask_idx), mask_idx)\n",
    "        print(\"masked label:\", len(mask_label), mask_label)\n",
    "        \n",
    "        instance = {\n",
    "            \"tokens\": tokens,\n",
    "            \"segment\": segment,\n",
    "            \"is_next\": is_next,\n",
    "            \"mask_idx\": mask_idx,\n",
    "            \"mask_label\": mask_label\n",
    "        }\n",
    "        instances.append(instance)\n",
    "        ################################################\n",
    "        print()\n",
    "        \n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-findings",
   "metadata": {},
   "source": [
    "최종 완성된 데이터셋의 결과는 다음과 같이 나타납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dominican-translator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', '▁퇴', '근', '▁후', '▁각자의', '▁공간에서', '[MASK]', '[MASK]', '▁화', '상', '▁모임', '의', '▁주된', '▁활동은', '▁국', '학', '기', '공', '▁수련', '이다', '.', '[MASK]', '[MASK]', '▁마음의', '▁고', '단', '함을', '[SEP]', '▁수련', '으로', '▁비', '우고', '▁회복', '하는', '▁대만', '澗', '▁시간', '이다', '.', '▁간단한', '▁동작을', '[MASK]', '▁호흡', '과', '▁어우러', '지는', '▁몸의', '▁움직임을', '▁느끼', '며', '▁몸', '과', '▁마음을', '▁지금', '▁이곳에', '▁머물', '도록', '▁하는', '▁시', '공간', '적', '▁집중', '상태', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 6, 7, 21, 22, 34, 35, 41], 'mask_label': ['▁어두운', '▁끝날', '▁것', '▁지나면', '▁서', '▁모든']}\n",
      "{'tokens': ['[CLS]', '▁어느', '▁정도', '▁호흡', '이', '▁정리', '되면', '▁머리가', '▁맑', '아', '지고', '▁몸', '도', '▁가벼', '워', '진', '▁상태에서', '[MASK]', '▁선생님', '들의', '▁국', '학', '기', '공', '▁교육', '▁활동', '▁사례를', '[SEP]', '[MASK]', '▁시간을', '▁갖는다', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [17, 18, 19, 28], 'mask_label': ['▁어두운', '▁끝날', '▁것', '▁지나면', '▁서', '▁모든']}\n"
     ]
    }
   ],
   "source": [
    "# 최종 데이터셋 결과 확인\n",
    "for instance in instances:\n",
    "    print(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-faith",
   "metadata": {},
   "source": [
    "### create_pretrain_instances() : Next Sentence Prediction을 위한 코퍼스 생성 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "emerging-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
    "    \"\"\"\n",
    "    doc별 pretrain 데이터 생성\n",
    "    \"\"\"\n",
    "    # for CLS], [SEP], [SEP]\n",
    "    max_seq = n_seq - 3\n",
    "\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i])  # line\n",
    "        current_length += len(doc[i])\n",
    "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):\n",
    "            # token a\n",
    "            a_end = 1\n",
    "            if 1 < len(current_chunk):\n",
    "                a_end = random.randrange(1, len(current_chunk))\n",
    "            tokens_a = []\n",
    "            for j in range(a_end):\n",
    "                tokens_a.extend(current_chunk[j])\n",
    "            # token b\n",
    "            tokens_b = []\n",
    "            for j in range(a_end, len(current_chunk)):\n",
    "                tokens_b.extend(current_chunk[j])\n",
    "\n",
    "            if random.random() < 0.5:  # 50% 확률로 swap\n",
    "                is_next = 0\n",
    "                tokens_t = tokens_a\n",
    "                tokens_a = tokens_b\n",
    "                tokens_b = tokens_t\n",
    "            else:\n",
    "                is_next = 1\n",
    "            # max_seq 보다 큰 경우 길이 조절\n",
    "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "            assert 0 < len(tokens_a)\n",
    "            assert 0 < len(tokens_b)\n",
    "            # tokens & aegment 생성\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "            # mask\n",
    "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
    "\n",
    "            instance = {\n",
    "                \"tokens\": tokens,\n",
    "                \"segment\": segment,\n",
    "                \"is_next\": is_next,\n",
    "                \"mask_idx\": mask_idx,\n",
    "                \"mask_label\": mask_label\n",
    "            }\n",
    "            instances.append(instance)\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-fence",
   "metadata": {},
   "source": [
    "create_pretrain_instances() 수행 결과를 다시 한번 확인해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "patient-colony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', '▁시간', '이다', '.', '▁간단한', '▁동작을', '[MASK]', '▁호흡', '과', '▁어우러', '지는', '▁몸의', '▁움직임을', '▁느끼', '며', '▁몸', '과', '[MASK]', '▁지금', '▁이곳에', '▁머물', '도록', '▁하는', '▁시', '공간', '적', '▁집중', '상태', '로', '[MASK]', '[MASK]', '▁편안', '한', '▁분위기가', '[MASK]', '[MASK]', '[SEP]', '체의', '▁치안', '▁후', '[MASK]', '▁공간에서', '▁참석', '하는', '▁화', '상', '▁모임', '의', '▁주된', '▁활동은', '▁국', '학', '기', '공', '▁수련', '이다', '.', '▁몸', '과', '▁마음의', '▁고', '단', '함을', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [6, 17, 29, 30, 34, 35, 37, 38, 40], 'mask_label': ['▁하면서', '▁마음을', '▁한', '결', '▁된다', '.', '▁퇴', '근', '▁각자의']}\n",
      "{'tokens': ['[CLS]', '[MASK]', '▁정도', '▁호흡', '이', '[MASK]', '[MASK]', '▁머리가', '▁맑', '아', '지고', '▁몸', '도', '▁가벼', '워', '진', '▁상태에서', '▁몇몇', '▁선생님', '들의', '▁국', '학', '기', '공', '▁교육', '▁활동', '▁사례를', '[SEP]', '▁공유하는', '[MASK]', '▁갖는다', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 5, 6, 29], 'mask_label': ['▁어느', '▁정리', '되면', '▁시간을']}\n"
     ]
    }
   ],
   "source": [
    "instances = create_pretrain_instances(vocab, doc, n_test_seq, 0.15, vocab_list)\n",
    "\n",
    "# 최종 데이터셋 결과 확인\n",
    "for instance in instances:\n",
    "    print(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-roads",
   "metadata": {},
   "source": [
    "## 데이터 전처리 : 데이터셋 완성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-uncle",
   "metadata": {},
   "source": [
    "이제 우리가 다루어야 할 **kowiki.txt**에 대해 본격적으로 살펴보고자 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cellular-rochester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3957761"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "\n",
    "# line count 확인\n",
    "total = 0\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    for line in in_f:\n",
    "        total += 1\n",
    "\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-kitty",
   "metadata": {},
   "source": [
    "전체 라인 수가 거의 400만 개에 육박합니다. 어마어마하게 데이터가 많습니다.\n",
    "\n",
    "한편, **위키 문서는 하나의 도큐먼트가 주제 키워드에 대해 상세 내용이 설명으로 따라붙어 있는 형태**로 구성되어 있습니다.\n",
    "\n",
    "도큐먼트 주제별로 잘 나눠지는지도 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "egyptian-civilian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50223598942449d81b7a8d376fea6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 lines : ['▁지미', '▁카터']\n",
      "['▁제임스', '▁얼', '▁\"', '지', '미', '\"', '▁카터', '▁주니어', '(,', '▁1924', '년', '▁10', '월', '▁1', '일', '▁~', '▁)', '는', '▁민주당', '▁출신', '▁미국', '▁39', '번째', '▁대통령', '▁(19', '77', '년', '▁~', '▁1981', '년', ')', '이다', '.']\n",
      "['▁그는', '▁2002', '년', '▁말', '▁인권', '과', '▁중재', '▁역할에', '▁대한', '▁공로를', '▁인정받아', '▁노벨', '▁평화', '상을', '▁받게', '▁되었다', '.']\n",
      "\n",
      "14 lines : ['▁수학']\n",
      "['▁수학', '(', '數', '學', ',', '▁)', '은', '▁양', ',', '▁구조', ',', '▁공간', ',', '▁변화', ',', '▁미', '적', '분', '▁등의', '▁개념을', '▁다루는', '▁학문이다', '.', '▁현대', '▁수학', '은', '▁형식', '▁논', '리를', '▁이용해서', '▁공', '리로', '▁구성된', '▁추상', '적', '▁구조를', '▁연구하는', '▁학문', '으로', '▁여겨', '지기도', '▁한다', '.', '▁수학', '은', '▁그', '▁구조와', '▁발전', '▁과정', '에서는', '▁자연', '과학', '에', '▁속하는', '▁물리', '학을', '▁비롯한', '▁다른', '▁학문', '들과', '▁깊은', '▁연', '관을', '▁맺고', '▁있다', '.', '▁하지만', ',', '▁어느', '▁과학의', '▁분야', '들과는', '▁달리', ',', '▁자연', '계에서', '▁관측', '되지', '▁않는', '▁개념', '들에', '▁대해서', '까지', '▁이론을', '▁일반화', '▁및', '▁추상', '화', '시킬', '▁수', '▁있다는', '▁차이가', '▁있다고', '▁한다', '.', '▁수', '학자들은', '▁그러한', '▁개념', '들에', '▁대해서', '▁추측', '을', '▁하고', ',', '▁적절', '하게', '▁선택', '된', '▁정의', '와', '▁공리', '로부터의', '▁엄', '밀한', '▁연', '역을', '▁통해서', '▁추측', '들의', '▁진', '위를', '▁파악', '한다', '.']\n",
      "['▁수', '학의', '▁기초를', '▁확실히', '▁세우', '기', '▁위해', ',', '▁수리', '논', '리', '학과', '▁집합', '론이', '▁발전', '하였고', ',', '▁이와', '▁더불어', '▁범주', '론이', '▁최근', '에도', '▁발전', '되고', '▁있다', '.', '▁“', '근', '본', '▁위기', '”', '라는', '▁말은', '▁대략', '▁1900', '년에서', '▁1930', '년', '▁사이에', '▁일어난', ',', '▁수', '학의', '▁엄', '밀한', '▁기초', '에', '▁대한', '▁탐', '구를', '▁상징', '적으로', '▁보여주는', '▁말이다', '.', '▁수', '학의', '▁엄', '밀한', '▁기초', '에', '▁대한', '▁몇', '▁가지', '▁의견', '▁불', '일', '치는', '▁오늘날에도', '▁계속되고', '▁있다', '.', '▁수', '학의', '▁기초', '에', '▁대한', '▁위', '기는', '▁그', '▁당시', '▁수많은', '▁논쟁', '에', '▁의해', '▁촉발', '되었으며', ',', '▁그', '▁논쟁', '에는', '▁칸', '토', '어의', '▁집합', '론과', '▁브라우', '어', '-', '힐', '베르트', '▁논쟁이', '▁포함되었다', '.']\n",
      "\n",
      "4 lines : ['▁수학', '▁상수']\n",
      "['▁수학에서', '▁상수', '란', '▁그', '▁값이', '▁변하지', '▁않는', '▁불변', '량으로', ',', '▁변', '수의', '▁반대', '말', '이다', '.', '▁물리', '▁상수', '와는', '▁달리', ',', '▁수학', '▁상', '수는', '▁물리적', '▁측정', '과는', '▁상관없이', '▁정의된다', '.']\n",
      "['▁특정', '▁수학', '▁상수', ',', '▁예를', '▁들면', '▁골', '롬', '-', '딕', '맨', '▁상수', ',', '▁프랑', '세', '즈', '-', '로', '빈', '슨', '▁상수', ',', '▁formula', '_1', ',', '▁레', '비', '▁상수', '같은', '▁상', '수는', '▁다른', '▁수학', '상수', '▁또는', '▁함수', '와', '▁약한', '▁상관', '관계', '▁또는', '▁강한', '▁상관', '관계를', '▁갖는다', '.']\n",
      "\n",
      "10 lines : ['▁문학']\n",
      "['▁문학', '(', '文', '學', ')', '은', '▁언어를', '▁예술적', '▁표현의', '▁제', '재로', '▁삼아', '▁새로운', '▁의미를', '▁창출', '하여', ',', '▁인간과', '▁사회를', '▁진실', '되게', '▁묘사', '하는', '▁예술의', '▁하위', '분야', '이다', '.', '▁간단하게', '▁설명', '하면', ',', '▁언어를', '▁통해', '▁인간의', '▁삶을', '▁미', '적', '(', '美', '的', ')', '으로', '▁형상', '화한', '▁것이라고', '▁볼', '▁수', '▁있다', '.', '▁문학', '은', '▁원래', '▁문예', '(', '文', '藝', ')', '라고', '▁부르는', '▁것이', '▁옳', '으며', ',', '▁문학을', '▁학문의', '▁대상', '으로서', '▁탐구', '하는', '▁학문의', '▁명칭', '▁역시', '▁문예', '학', '이다', '.', '▁문예', '학은', '▁음악', '사', '학', ',', '▁미술', '사', '학', '▁등과', '▁함께', '▁예술', '학의', '▁핵심', '분야', '로서', '▁인문', '학의', '▁하위', '범', '주에', '▁포함된다', '.']\n",
      "['▁반영', '론적', '▁관', '점에', '▁의한', '▁감', '상은', '▁작품을', '▁창작', '된', '▁당시', '▁시대', '▁정', '황', '과', '▁연결', '시켜', '▁감상', '하는', '▁입장', '이고', ',', '▁내재', '적', '▁관', '점의', '▁감', '상은', '▁작품의', '▁형식', ',', '▁내용에', '▁국한', '하여', '▁감상', '하는', '▁것이다', '.', '▁표현', '론적', '▁관', '점의', '▁감', '상은', '▁작가의', '▁전기', '적', '▁사실과', '▁작품을', '▁연결', '시켜', '▁감상', '하는', '▁것이고', ',', '▁수용', '론적', '▁관', '점의', '▁감', '상은', '▁독', '자와', '▁작품을', '▁연결', '시켜', '▁감상', '하는', '▁것을', '▁말한다', '.']\n",
      "\n",
      "10 lines : ['▁나라', '▁목록']\n",
      "['▁이', '▁문서는', '▁나라', '▁목록', '이며', ',', '▁전', '▁세계', '▁20', '6', '개', '▁나라의', '▁각', '▁현황', '과', '▁주권', '▁승인', '▁정보를', '▁개', '요', '▁형태로', '▁나열', '하고', '▁있다', '.']\n",
      "['▁위', '▁목록에', '▁포함되지', '▁않은', '▁다음', '▁국가는', '▁몬테', '비', '데오', '▁협약', '의', '▁모든', '▁조건을', '▁만족', '하지', '▁못', '하거나', ',', '▁자주', '적이고', '▁독립', '적', '임을', '▁주장', '하지', '▁않는', '▁국가이다', '.']\n",
      "\n",
      "['▁화학']\n",
      "['▁화학', '(', '化', '學', ',', '▁)', '은', '▁물질의', '▁성질', ',', '▁조성', ',', '▁구조', ',', '▁변화', '▁및', '▁그에', '▁수반', '하는', '▁에너지의', '▁변화를', '▁연구하는', '▁자연과', '학의', '▁한', '▁분야이다', '.', '▁물리학', '도', '▁역시', '▁물질을', '▁다루는', '▁학문', '이지만', ',', '▁물리학', '이', '▁원', '소와', '▁화합', '물을', '▁모두', '▁포함한', '▁물체의', '▁운동과', '▁에너지', ',', '▁열', '적', '·', '전기', '적', '·', '광', '학적', '·', '기계', '적', '▁속', '성을', '▁다루고', '▁이러한', '▁현상', '으로부터', '▁통일된', '▁이론을', '▁구축', '하려는', '▁것과는', '▁달리', '▁화학', '에서는', '▁물질', '▁자체를', '▁연구', '▁대상으로', '▁한다', '.', '▁화학', '은', '▁이미', '▁존재하는', '▁물질을', '▁이용하여', '▁특정한', '▁목적에', '▁맞는', '▁새로운', '▁물질을', '▁합성', '하는', '▁길을', '▁제공하며', ',', '▁이는', '▁농작', '물의', '▁증', '산', ',', '▁질병의', '▁치료', '▁및', '▁예방', ',', '▁에너지', '▁효율', '▁증대', ',', '▁환경', '오', '염', '▁감소', '▁등', '▁여러', '▁가지', '▁이', '점을', '▁제공한다', '.']\n",
      "['▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '▁화합', '물의', '▁범위가', '▁크게', '▁넓', '어져', '▁탄소', '▁사슬', '▁또는', '▁탄소', '▁고', '리를', '▁가진', '▁모든', '▁화합', '물을', '▁뜻한다', '.', '▁유기', '화', '학의', '▁오랜', '▁관심', '사는', '▁유기', '▁화합', '물의', '▁합성', '▁메커니즘', '이다', '.', '▁현대에', '▁들어서', '▁핵', '자기', '▁공명', '법과', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.']\n"
     ]
    }
   ],
   "source": [
    "# 위키가 주제별로 잘 나눠지는지 여부 확인\n",
    "count = 5\n",
    "\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    doc = []  # 단락 단위로 문서 저장\n",
    "    for line in tqdm(in_f, total=total):\n",
    "        line = line.strip()\n",
    "        if line == \"\":  # line이 빈줄 일 경우 (새로운 단락을 의미 함)\n",
    "            if 0 < len(doc):\n",
    "                if 0 < count:\n",
    "                    count -= 1\n",
    "                    print(len(doc), \"lines :\", doc[0])\n",
    "                    print(doc[1])\n",
    "                    print(doc[-1])\n",
    "                    print()\n",
    "                else:\n",
    "                    break\n",
    "                doc = []\n",
    "        else:  # doc에 저장\n",
    "            pieces = vocab.encode_as_pieces(line)\n",
    "            if 0 < len(pieces):\n",
    "                doc.append(pieces)\n",
    "    if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "        print(doc[0])\n",
    "        print(doc[1])\n",
    "        print(doc[-1])\n",
    "        doc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-auckland",
   "metadata": {},
   "source": [
    "이전 스텝에서 완성했던 **create_pretrain_instances()** 를 코퍼스에 적용할 수 있는지 몇 라인에 대해서만 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "american-flight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d994ac506c20417594dd46d084a4ef5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: 21 instances: 10\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', '▁있어서', '[MASK]', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '[MASK]', '[MASK]', '[MASK]', '▁탄', '소로', '▁이루어진', '[MASK]', '[MASK]', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '[MASK]', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [12, 15, 16, 33, 34, 35, 39, 40, 61], 'mask_label': ['▁매우', '▁자리잡았다', '.', '▁유기', '화', '학은', '▁화합', '물을', '▁지금은']}\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '[MASK]', '▁유기', '▁화합물', '▁분석', '에', '[MASK]', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '[MASK]', '[MASK]', '[MASK]', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '[MASK]', '[MASK]', '▁이루어진', '▁화합', '물을', '[MASK]', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [5, 6, 11, 22, 23, 24, 36, 37, 41], 'mask_label': ['▁등이', '▁개발되어', '▁있어서', '▁고분', '자', '물질', '▁탄', '소로', '▁연구하는']}\n",
      "\n",
      "doc: 14 instances: 7\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '[MASK]', '▁화합물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '[MASK]', '[MASK]', '[MASK]', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '[MASK]', '[MASK]', '▁연구하는', '▁분', '과', '이다', '.', '[MASK]', '▁유기', '▁화합', '물은', '▁식물', '이나', '[MASK]', '[MASK]', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [7, 26, 27, 28, 39, 40, 46, 52, 53], 'mask_label': ['▁유기', '▁유기', '화', '학에서', '▁화합', '물을', '▁원래', '▁동물', '로부터']}\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '믹스', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '[MASK]', '▁화합', '물을', '▁연구하는', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '貪', '▁반사', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [7, 25, 38, 42, 43, 44, 45, 52, 53], 'mask_label': ['▁유기', '▁등도', '▁이루어진', '▁분', '과', '이다', '.', '▁동물', '로부터']}\n",
      "\n",
      "doc: 4 instances: 2\n",
      "{'tokens': ['[CLS]', '87', '▁돌아간다', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', 'ᅮ', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁다쓰', '▁세바', '로만', '▁강은', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '[MASK]', '[MASK]', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 11, 42, 43, 44, 45, 59, 60], 'mask_label': ['▁X', '선', '▁있어서', '▁분', '과', '이다', '.', '▁뜻', '하였으나']}\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '[MASK]', '[MASK]', '[MASK]', '▁다루', '어진다', '.', '[SEP]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '[MASK]', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [26, 27, 28, 33, 34, 35, 36, 37, 46], 'mask_label': ['▁유기', '화', '학에서', '▁유기', '화', '학은', '▁탄', '소로', '▁원래']}\n",
      "\n",
      "doc: 10 instances: 5\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '[MASK]', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '[MASK]', '[MASK]', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '[MASK]', '[MASK]', '[MASK]', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '[MASK]', '[MASK]', '▁뜻', '하였으나', '[MASK]', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [8, 15, 16, 47, 48, 49, 57, 58, 61], 'mask_label': ['▁화합물', '▁자리잡았다', '.', '▁유기', '▁화합', '물은', '▁화합', '물을', '▁지금은']}\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '▁유기', '▁화합물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '[MASK]', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '[MASK]', '[MASK]', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [19, 20, 21, 22, 23, 24, 38, 52, 53], 'mask_label': ['▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁이루어진', '▁동물', '로부터']}\n",
      "\n",
      "doc: 10 instances: 5\n",
      "{'tokens': ['[CLS]', '▁X', '선', '[MASK]', '[MASK]', '▁등이', '▁개발되어', '▁유기', '[MASK]', '▁분석', '에', '[MASK]', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁81', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '[MASK]', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [3, 4, 8, 11, 38, 47, 54, 55, 56], 'mask_label': ['▁결정', '학', '▁화합물', '▁있어서', '▁이루어진', '▁유기', '▁추출', '해', '낸']}\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '[MASK]', '▁유기', '▁화합물', '▁분석', '에', '[MASK]', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '[MASK]', '[MASK]', '[MASK]', '▁고분', '자', '물질', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '[MASK]', '[MASK]', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '[MASK]', '[MASK]', '▁지금은', '▁유기', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [6, 11, 19, 20, 21, 36, 37, 59, 60], 'mask_label': ['▁개발되어', '▁있어서', '▁합성', '섬유', '등의', '▁탄', '소로', '▁뜻', '하였으나']}\n",
      "\n",
      "doc: 31 instances: 15\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '▁개발되어', '[MASK]', '▁화합물', '[MASK]', '[MASK]', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '▁고분', '자', '물질', '[MASK]', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁사회복지', '▁유기', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '▁뜻', '하였으나', '▁지금은', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 7, 9, 10, 25, 38, 46, 62], 'mask_label': ['▁X', '선', '▁유기', '▁분석', '에', '▁등도', '▁이루어진', '▁원래', '▁유기']}\n",
      "{'tokens': ['[CLS]', '▁X', '선', '▁결정', '학', '▁등이', '[MASK]', '▁유기', '[MASK]', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법으로', '▁자리잡았다', '.', '▁플라스틱', ',', '▁합성', '섬유', '등의', '[MASK]', '[MASK]', '[MASK]', '▁등도', '▁유기', '화', '학에서', '▁다루', '어진다', '.', '[SEP]', '▁유기', '화', '학은', '▁탄', '소로', '▁이루어진', '▁화합', '물을', '▁연구하는', '▁분', '과', '이다', '.', '▁원래', '[MASK]', '▁화합', '물은', '▁식물', '이나', '▁동물', '로부터', '▁추출', '해', '낸', '▁화합', '물을', '[MASK]', '[MASK]', '▁지금은', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [6, 8, 22, 23, 24, 47, 59, 60, 62], 'mask_label': ['▁개발되어', '▁화합물', '▁고분', '자', '물질', '▁유기', '▁뜻', '하였으나', '▁유기']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instance 생성 기능 확인\n",
    "count = 5\n",
    "\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    doc = []  # 단락 단위로 문서 저장\n",
    "    for line in tqdm(in_f, total=total):\n",
    "        line = line.strip()\n",
    "        if line == \"\":  # line이 빈줄 일 경우 (새로운 단락을 의미 함)\n",
    "            if 0 < len(doc):\n",
    "                instances = create_pretrain_instances(vocab, doc, n_test_seq, 0.15, vocab_list)\n",
    "                # save\n",
    "                print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "                print(instances[0])\n",
    "                print(instances[-1])\n",
    "                print()\n",
    "                doc = []\n",
    "                if 0 < count:  # 테스트를 위해서 부분 처리 함\n",
    "                    count -= 1\n",
    "                else:\n",
    "                    break\n",
    "        else:  # doc에 저장\n",
    "            if 0 < len(pieces):\n",
    "                doc.append(pieces)\n",
    "    if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "        instances = create_pretrain_instances(doc, 128)\n",
    "        # save\n",
    "        print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "        print(instances[0])\n",
    "        print(instances[-1])\n",
    "        print()\n",
    "        doc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-button",
   "metadata": {},
   "source": [
    "### make_pretrain_data() : BERT pretrain 데이터셋 생성 메소드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-sequence",
   "metadata": {},
   "source": [
    "전체 전처리 과정을 거쳐 최종적으로 만들어지는 BERT pretrain 데이터셋 생성 메소드는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "japanese-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
    "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
    "    def save_pretrain_instances(out_f, doc):\n",
    "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
    "        for instance in instances:\n",
    "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "            out_f.write(\"\\n\")\n",
    "\n",
    "    # 특수문자 7개를 제외한 vocab_list 생성\n",
    "    vocab_list = []\n",
    "    for id in range(7, len(vocab)):\n",
    "        if not vocab.is_unknown(id):\n",
    "            vocab_list.append(vocab.id_to_piece(id))\n",
    "\n",
    "    # line count 확인\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        with open(out_file, \"w\") as out_f:\n",
    "            doc = []\n",
    "            for line in tqdm(in_f, total=line_cnt):\n",
    "                line = line.strip()\n",
    "                if line == \"\":  # line이 빈줄 일 경우 (새로운 단락을 의미 함)\n",
    "                    if 0 < len(doc):\n",
    "                        save_pretrain_instances(out_f, doc)\n",
    "                        doc = []\n",
    "                else:  # line이 빈줄이 아닐 경우 tokenize 해서 doc에 저장\n",
    "                    pieces = vocab.encode_as_pieces(line)\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "            if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "                save_pretrain_instances(out_f, doc)\n",
    "                doc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-conclusion",
   "metadata": {},
   "source": [
    "이제 약 400만 라인에 해당하는 전체 코퍼스에 대해 **make_pretrain_data()** 를 구동시켜 봅니다. 약 10여분 가량 시간이 소요될 수 있습니다.\n",
    "\n",
    "최종적으로 생성된 데이터셋은 json 포맷으로 저장될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cooperative-queens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935065a5184a4802928ff060b1e443aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrain_json_path = os.getenv('HOME')+'/aiffel/bert_pretrain/data/bert_pre_train.json'\n",
    "\n",
    "make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "third-documentary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862285"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# line 수 확인\n",
    "total = 0\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        total += 1\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-equity",
   "metadata": {},
   "source": [
    "데이터셋 파일을 만드는 것까지 진행해 보았습니다.\n",
    "\n",
    "하지만 여기서 고려해야 할 점이 있습니다. 우리가 다루어야 할 데이터셋은 사이즈가 큽니다. 만들어질 json 데이터파일의 크기가 1.4GB 정도 됩니다. 실제 BERT 학습용의 백 분의 일 사이즈 정도밖에 안 되겠지만 그럼에도 불구하고 이렇게 큰 파일을 로딩하는 함수를 만들 때는 메모리 사용량과 관련해 고려해야 할 점이 있습니다.\n",
    "\n",
    "그래서 우리는 넘파이의 **np.memmap**을 사용해서 메모리 사용량을 최소화하는 방법을 시도해 볼 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "lasting-aquarium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 0,\n",
       " 0,\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seq = 128\n",
    "# [CLS], tokens_a, [SEP], tokens_b, [SEP]\n",
    "max_seq = n_seq - 3\n",
    "\n",
    "# 만약 일반적인 Numpy Array에다 데이터를 로딩한다면 이렇게 되겠지만\n",
    "# enc_tokens = np.zeros((total, n_seq), np.int32)\n",
    "# dec_tokens = np.zeros((total, n_seq), np.int32)\n",
    "# labels_nsp = np.zeros((total,), np.int32)\n",
    "# labels_mlm = np.zeros((total, n_seq), np.int32)\n",
    "\n",
    "# np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "\n",
    "enc_tokens[0], enc_tokens[-1], segments[0], segments[-1], labels_nsp[0], labels_nsp[-1], labels_mlm[0], labels_mlm[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-gross",
   "metadata": {},
   "source": [
    "만들어진 json 파일을 라인 단위로 읽어 들여 np.memmap에 로딩해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "reliable-asian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b925f52a18b844b08b9869dd4dc98170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/862285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', '▁\"', '땅', '콩', '▁농부', '\"', '▁(', 'P', 'ean', 'ut', '▁F', 'ar', 'mer', ')', '로', '[MASK]', '[MASK]', '▁1962', '년', '▁조지아', '[MASK]', '[MASK]', '▁의원', '▁선거에서', '[MASK]', '[MASK]', '▁그', '▁선거가', '▁부정', '선거', '▁', '였', '음을', '▁입증', '하게', '▁되어', '▁당선', '되고', ',', '▁1966', '년', '[MASK]', '▁주', '▁지사', '▁선거에', '▁낙선', '하지만', '▁1970', '년', '▁조지아', '[MASK]', '▁지', '사를', '▁역임했다', '.', '▁대통령이', '▁되기', '▁전', '▁조지아', '주', '▁상원의', '원을', '▁두', '번', '▁연', '임', '했으며', ',', '▁1971', '년부터', '▁1975', '년까지', '▁조지아', '▁지', '사로', '▁근무했다', '.', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁미국에', '▁사는', '▁흑인', '▁등용', '법을', '▁내세', '웠다', '.', '[SEP]', '▁지미', '[MASK]', '▁제임스', '▁얼', '▁\"', '지', '미', '\"', '▁카터', '▁주니어', '(,', '[MASK]', '[MASK]', '▁10', '월', '▁1', '일', '▁~', '▁)', '는', '▁민주당', '[MASK]', '▁미국', '▁39', '번째', '▁대통령', '▁(19', '77', '년', '▁~', '▁1981', '년', ')', '이다', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [15, 16, 20, 21, 24, 25, 41, 50, 77, 78, 79, 80, 81, 82, 93, 103, 104, 113], 'mask_label': ['▁알려졌다', '.', '▁주', '▁상원', '▁낙선', '하나', '▁조지아', '▁주', '▁조지아', '▁주지', '사로', '▁지내', '면서', ',', '▁카터', '▁1924', '년', '▁출신']}\n",
      "enc_token: [5, 103, 28313, 28290, 19041, 27718, 98, 27878, 15784, 2543, 309, 337, 5771, 27616, 27603, 6, 6, 3715, 27625, 5551, 6, 6, 2378, 5249, 6, 6, 13, 20590, 2386, 2163, 27596, 27671, 969, 8047, 173, 607, 2387, 317, 27604, 3926, 27625, 6, 37, 18995, 8198, 9858, 1447, 1921, 27625, 5551, 6, 18, 451, 4267, 27599, 4864, 6436, 25, 5551, 27646, 18205, 928, 157, 27821, 61, 27773, 530, 27604, 3372, 523, 3409, 673, 5551, 18, 982, 13264, 27599, 6, 6, 6, 6, 6, 6, 6945, 3554, 6719, 12788, 2046, 5890, 1853, 27599, 4, 16415, 6, 3324, 1042, 103, 27610, 27686, 27718, 25250, 7504, 416, 6, 6, 131, 27662, 7, 27629, 203, 241, 27602, 4867, 6, 243, 5898, 796, 663, 1647, 4630, 27625, 203, 3008, 27625, 27616, 16, 27599, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 0\n",
      "label_mlm: [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0  4578 27599     0     0     0    37 11234     0     0\n",
      "  9858  3294     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0  5551     0     0     0     0     0     0\n",
      "     0     0    37     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0  5551  5053   982  4739   151 27604     0\n",
      "     0     0     0     0     0     0     0     0     0 25250     0     0\n",
      "     0     0     0     0     0     0     0  5708 27625     0     0     0\n",
      "     0     0     0     0     0   788     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', '▁에너지', '[MASK]', '▁촉구', '했으나', '▁공화', '당의', '▁반대로', '▁무산되었다', '.', '▁카', '터는', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁조정', '하여', ',', '▁캠프', '▁데이비', '드에서', '▁안', '와', '르', '▁사다', '트', '▁대통령과', '▁메', '나', '헴', '▁베', '긴', '▁수상', '과', '▁함께', '[MASK]', '▁평화를', '▁위한', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁협정을', '▁체결했다', '.', '▁그러나', '[MASK]', '▁공화', '당과', '▁미국의', '▁유대인', '▁단체의', '▁반발을', '▁일으켰다', '.', '▁1979', '년', '▁백악', '관에서', '▁양국', '▁간의', '▁평화', '조약', '으로', '▁이끌', '어졌다', '.', '▁또한', '▁소련과', '▁제', '2', '차', '▁전략', '▁무기', '▁제한', '▁협', '상에', '[MASK]', '[MASK]', '[MASK]', '▁카', '터는', '▁1970', '년대', '▁후반', '[MASK]', '▁대한민국', '▁등', '▁인권', '▁후진', '국의', '▁국민들의', '▁인', '권을', '▁지키기', '[MASK]', '▁노력', '했으며', ',', '▁취임', '▁이후', '▁계속해서', '▁도덕', '정', '치를', '▁내세', '웠다', '.', '[SEP]', '▁1976', '년', '▁대통령', '▁선거에', '▁민주당', '▁후보로', '▁출마하여', '▁도덕', '주의', '▁정책으로', '▁내세워', ',', '▁포', '드를', '▁누르고', '▁당선되었다', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [2, 12, 13, 14, 15, 36, 39, 40, 41, 42, 47, 78, 79, 80, 86, 96, 122, 123], 'mask_label': ['▁개발을', '▁이집', '트와', '▁이스라엘', '을', '▁중동', '▁캠프', '데이', '비', '드', '▁이것은', '▁조인', '했다', '.', '▁당시', '▁위해', '▁포', '드를']}\n",
      "enc_token: [5, 3634, 6, 9747, 1003, 4460, 1547, 4771, 18474, 27599, 207, 4612, 6, 6, 6, 6, 3358, 54, 27604, 10251, 3640, 3552, 172, 27665, 27699, 7025, 27677, 13799, 334, 27637, 29887, 271, 28099, 1011, 27644, 280, 6, 14237, 521, 6, 6, 6, 6, 15990, 19102, 27599, 330, 6, 4460, 4040, 679, 7455, 15747, 21408, 6564, 27599, 2995, 27625, 10312, 6749, 13195, 2714, 2793, 8993, 9, 1435, 2521, 27599, 276, 23197, 30, 27619, 27751, 2835, 3841, 1956, 617, 1824, 6, 6, 6, 207, 4612, 1921, 596, 1840, 6, 410, 50, 5636, 17092, 137, 18896, 42, 917, 15177, 6, 3375, 530, 27604, 2659, 165, 6357, 6244, 27642, 1233, 5890, 1853, 27599, 4, 3306, 27625, 663, 8198, 4867, 4896, 19160, 6244, 238, 22033, 19990, 27604, 119, 1486, 10071, 7965, 27599, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 0\n",
      "label_mlm: [    0     0  8085     0     0     0     0     0     0     0     0     0\n",
      "  2703  3604  3426 27607     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "  8021     0     0 10251  4282 27694 27681     0     0     0     0  1487\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0 15876    31 27599     0     0     0\n",
      "     0     0   316     0     0     0     0     0     0     0     0     0\n",
      "   231     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0   119  1486     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', '▁그러나', '▁주', '▁이란', '▁미국', '▁대사관', '▁인', '질', '▁사건에서', '▁인', '질', '▁구출', '[MASK]', '▁이유로', '[MASK]', '[MASK]', '[MASK]', '▁선거에서', '[MASK]', '[MASK]', '▁로', '널드', '▁레이', '건', '▁후보', '에게', '▁', '져', '▁결국', '▁재', '선에', '▁실패했다', '.', '▁또한', '▁임기', '▁말기에', '▁터', '진', '▁소련의', '▁아프가니스탄', '▁침공', '▁사건으로', '▁인해', '▁1980', '년', '▁하계', '▁올림픽에', '▁반공', '국가', '들의', '▁보이', '콧', '을', '▁내세', '웠다', '.', '[SEP]', '▁지미', '▁카', '터는', '▁대한민국', '과의', '[MASK]', '[MASK]', '▁중요한', '▁영향을', '▁미', '쳤던', '▁대통령', '▁중', '▁하나다', '.', '▁인권', '▁문제와', '▁주한미', '군', '▁철수', '▁문제로', '▁한때', '▁한미', '▁관계가', '▁불편', '하기도', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁대한민국에', '▁대한', '▁북한의', '▁위협', '에', '▁대비해', '▁한미', '연합', '사를', '[MASK]', '[MASK]', '[MASK]', '▁1982', '년까지', '▁3', '단', '계에', '▁걸쳐', '▁주한미', '군을', '▁철수', '하기로', '▁했다', '.', '[MASK]', '▁주한미', '군', '사령', '부와', '▁정보', '기관', '·', '의', '회의', '▁반', '대에', '▁부딪', '혀', '▁주한미', '군은', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [12, 14, 15, 16, 18, 19, 62, 63, 74, 75, 83, 84, 85, 86, 96, 97, 98, 111], 'mask_label': ['▁실패를', '▁1980', '년', '▁대통령', '▁공화', '당의', '▁관계', '에서도', '▁주한미', '군', '▁했다', '.', '▁1978', '년', '▁창설', '하면서', ',', '▁그러나']}\n",
      "enc_token: [5, 330, 37, 3290, 243, 18590, 42, 27892, 23937, 42, 27892, 11560, 6, 1827, 6, 6, 6, 5249, 6, 6, 194, 8631, 1169, 27803, 958, 113, 27596, 27944, 875, 174, 2087, 9510, 27599, 276, 11034, 12145, 870, 27713, 5569, 7676, 3232, 6322, 751, 1640, 27625, 2219, 5825, 13948, 4398, 247, 3052, 28805, 27607, 5890, 1853, 27599, 4, 16415, 207, 4612, 410, 786, 6, 6, 1165, 1063, 55, 23859, 663, 35, 15550, 27599, 5636, 14964, 24438, 27722, 5337, 4875, 3590, 12259, 4857, 12019, 863, 6, 6, 6, 6, 11525, 92, 9305, 3038, 27600, 25557, 12259, 2569, 451, 6, 6, 6, 2760, 673, 49, 27737, 1949, 1633, 24438, 1262, 5337, 2390, 345, 27599, 6, 24438, 27722, 3069, 2576, 1071, 1468, 27873, 27601, 511, 141, 867, 11574, 28178, 24438, 941, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mlm: [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      " 22684     0  1640 27625   663     0  4460  1547     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0   704   643     0     0     0     0     0     0     0     0\n",
      "     0     0 24438 27722     0     0     0     0     0     0     0   345\n",
      " 27599  3331 27625     0     0     0     0     0     0     0     0     0\n",
      "  3574   421 27604     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0   330     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', ',', '▁박정희', '▁대통령이', '▁김재', '규', '▁중앙정보', '부', '장에', '▁의해', '▁살해', '된', '▁것에', '▁대해', '▁그는', '▁이', '▁사건으로', '▁큰', '▁충격을', '▁받았으며', ',', '▁사이', '러스', '▁밴', '스', '[MASK]', '[MASK]', '[MASK]', '▁조', '문사', '절로', '▁파견했다', '.', '▁12', '·', '12', '▁군사', '▁반란', '과', '▁5.', '17', '▁쿠데타', '에', '▁대해', '▁초기에는', '[MASK]', '▁비난', '했으나', ',', '▁미국', '▁정부가', '▁신군', '부를', '▁설득', '하는데', ',', '▁한계가', '▁있었고', '▁결국', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁태도를', '▁보이게', '▁됐다', '.', '[SEP]', '▁퇴임', '▁이후', '▁민간', '[MASK]', '▁적극', '▁활용한', '[MASK]', '▁기구', '인', '▁카터', '▁재', '단을', '[MASK]', '[MASK]', '▁민주주의', '▁실현', '을', '▁위해', '▁제', '▁3', '세계의', '▁선거', '▁감시', '▁활동', '▁및', '▁기니', '▁벌', '레', '에', '▁의한', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁질병', '▁방', '재를', '▁위해', '▁힘썼다', '.', '▁미국의', '▁빈곤', '층', '▁지원', '▁활동', ',', '▁사랑의', '▁집', '짓', '기', '▁운동', ',', '▁국제', '▁분쟁', '▁중재', '[MASK]', '▁활동도', '▁했다', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [25, 26, 27, 45, 59, 60, 61, 62, 70, 71, 74, 80, 81, 98, 99, 100, 101, 123], 'mask_label': ['▁국무', '장', '관을', '▁강하게', '▁묵', '인', '하는', '▁듯한', '▁민간', '▁자원을', '▁비영리', '▁설립한', '▁뒤', '▁드라', '쿤', '쿠르', '스', '▁등의']}\n",
      "enc_token: [5, 27604, 5298, 4864, 9918, 27958, 18525, 27638, 1312, 355, 2591, 27711, 2057, 433, 202, 8, 6322, 459, 10688, 5325, 27604, 328, 2086, 1228, 27626, 6, 6, 6, 53, 27181, 17544, 26520, 27599, 196, 27873, 1335, 1250, 2342, 27644, 11262, 1695, 14078, 27600, 433, 6797, 6, 3560, 1003, 27604, 243, 3840, 26826, 1191, 5523, 1294, 27604, 20984, 2492, 875, 6, 6, 6, 6, 11162, 16915, 3842, 27599, 4, 13826, 165, 3174, 6, 2929, 20639, 6, 6673, 27628, 25250, 174, 1574, 6, 6, 9889, 5031, 27607, 231, 30, 49, 21655, 822, 7049, 375, 228, 18137, 813, 27740, 27600, 1332, 6, 6, 6, 6, 5225, 95, 4445, 231, 19607, 27599, 679, 14197, 28083, 770, 375, 27604, 14003, 313, 28333, 27614, 887, 27604, 605, 4476, 13267, 6, 27328, 345, 27599, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mlm: [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0  4444 27651  1657     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0  7015     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0  5374\n",
      " 27628    38 10180     0     0     0     0     0     0     0  3174 17304\n",
      "     0     0 16068     0     0     0     0     0  7301   339     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0 17378 28956 16453 27626     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0   507     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', '▁초래', '한', '▁인물', '▁및', '[MASK]', '▁직접', '▁만나', '▁분쟁', '의', '▁원인을', '▁근본적으로', '▁해결하기', '▁위해', '▁힘썼다', '.', '▁이', '쓰고', '▁미국', '▁행정', '부와', '▁갈등을', '▁보이기도', '▁했지만', ',', '▁전직', '▁대통령의', '▁권한', '과', '[MASK]', '[MASK]', '▁유명', '▁인사', '들의', '▁활약으로', '▁해결', '해', '▁나갔다', '.', '▁1978', '년에', '▁채', '결', '된', '▁캠프', '데이', '비', '드', '[MASK]', '[MASK]', '▁이', '행이', '▁지지', '부', '진', '▁하자', '▁중동', '▁분쟁', '▁분', '제를', '▁해결하기', '▁위해', '[MASK]', '[MASK]', '▁퇴임', '▁후', '▁직접', '▁이스라엘', '과', '▁팔', '레인', '스타', '인의', '[MASK]', '▁협정을', '▁이끌어', '▁내는', '▁데', '도', '▁성공했다', '.', '[SEP]', '▁카', '터는', '▁카터', '▁행정부', '▁이후', '▁미국이', '▁북', '핵', '▁위기', ',', '[MASK]', '▁전쟁', ',', '[MASK]', '▁전쟁과', '▁같이', '▁미국이', '▁군사적', '▁행동을', '▁최후', '로', '▁선택하는', '▁전통적', '▁사고를', 'anc', '▁군사적', '▁행동을', '▁선행', '하는', '▁행위에', '[MASK]', '▁깊은', '[MASK]', '[MASK]', '▁표시', '▁하며', '▁국토교통', '▁군사적', '▁활동에', '▁강한', '▁반대', '[MASK]', '▁보이고', '▁있다', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [5, 17, 22, 29, 30, 48, 49, 62, 63, 73, 92, 95, 106, 112, 114, 115, 118, 123], 'mask_label': ['▁단체를', '▁과정에서', '▁보이기도', '▁재', '야', '▁협', '정의', '▁1993', '년', '▁오슬로', '▁코소보', '▁이라크', '▁버리고', '▁대해', '▁유', '감을', '▁미국의', '▁입장을']}\n",
      "enc_token: [5, 8200, 27612, 1178, 228, 6, 1069, 2142, 4476, 27601, 13635, 24806, 13425, 231, 19607, 27599, 8, 18948, 243, 895, 2576, 12627, 23828, 3379, 27604, 5605, 5744, 3753, 27644, 6, 6, 939, 3329, 247, 17462, 2317, 27645, 9946, 27599, 3331, 169, 481, 27783, 27711, 10251, 4282, 27694, 27681, 6, 6, 8, 7071, 1565, 27638, 27713, 3121, 8021, 4476, 147, 1104, 13425, 231, 6, 6, 13826, 81, 1069, 3426, 27644, 961, 5346, 936, 692, 6, 15990, 7027, 7573, 189, 27627, 6608, 27599, 4, 207, 4612, 25250, 21862, 165, 8424, 251, 28166, 10622, 27604, 6, 506, 27604, 6, 17305, 733, 8424, 9641, 5616, 12241, 27603, 26028, 15644, 13098, 11970, 9641, 5616, 16374, 38, 19690, 6, 4508, 6, 6, 2466, 1368, 20734, 9641, 8253, 2632, 1216, 6, 7010, 28, 27599, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 0\n",
      "label_mlm: [    0     0     0     0     0 19762     0     0     0     0     0     0\n",
      "     0     0     0     0     0  2208     0     0     0     0 23828     0\n",
      "     0     0     0     0     0   174 27775     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "   617  2028     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0  2062 27625     0     0     0     0     0     0     0     0\n",
      "     0 25213     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0 26202     0     0  6157\n",
      "     0     0     0     0     0     0     0     0     0     0  8275     0\n",
      "     0     0     0     0   433     0    46  2196     0     0   679     0\n",
      "     0     0     0  5168     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', '에서도', '▁관심이', '▁깊', '어', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁제도를', '▁시행', '하도록', '▁노력', '하여', '▁독재', '자들의', '▁인권', '▁사고가', '보장', '프트', '▁대해', '▁제', '약을', '▁하고', ',', '▁국제', '형사', '재판', '소를', '▁만드는', '▁데', '▁기여', '하여', '[MASK]', '[MASK]', '[MASK]', '▁인권', '유', '린', '범죄', '자를', '▁재판', '소로', '▁회', '부', '하여', '[MASK]', '▁처벌을', '▁받게', '▁하는', '▁등', '▁인권', '▁신', '장에', '▁크', '나', '▁큰', '▁기여를', '▁했다', '.', '[SEP]', '▁1993', '년', '▁1', '차', '▁북', '핵', '▁위기', '▁당시', '▁북한에', '[MASK]', '▁미국의', '▁군사적', '▁행동이', '▁임', '박', '했으나', ',', '▁미국', '▁전직', '▁대통령', '으로는', '▁처음으로', '▁북한', '을', '▁방문', '하고', '▁미국과', '▁북', '▁양국의', '▁중재', '에', '▁큰', '▁기여를', '▁해', '▁위기를', '▁해결', '했다는', '▁평가를', '▁받았다', '.', '▁또한', '▁이', '▁때', '[MASK]', '▁대통령과', '[MASK]', '▁주', '석의', '▁만남', '을', '▁주선', '했다', '.', '▁하지만', '▁그로부터', '▁수', '주일', '▁후', '▁김일', '성이', '▁갑자기', '▁사망하여', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [5, 6, 7, 8, 9, 10, 11, 12, 21, 22, 23, 37, 38, 39, 50, 74, 108, 110], 'mask_label': ['▁유엔', '에', '▁유엔', '인권', '고등', '판', '무', '관의', '▁유', '린', '에', '▁독재', '자들', '▁같은', '▁국제적인', '▁대한', '▁김영삼', '▁김일성']}\n",
      "enc_token: [5, 643, 8181, 1910, 27633, 6, 6, 6, 6, 6, 6, 6, 6, 6520, 2404, 1816, 3375, 54, 7559, 2653, 5636, 11555, 16311, 833, 433, 30, 3297, 644, 27604, 605, 17905, 4731, 1358, 3002, 189, 2187, 54, 6, 6, 6, 5636, 27690, 27870, 8822, 690, 2474, 2661, 270, 27638, 54, 6, 19956, 4256, 419, 50, 5636, 90, 1312, 252, 27637, 459, 13856, 345, 27599, 4, 2062, 27625, 7, 27751, 251, 28166, 10622, 316, 25086, 6, 679, 9641, 18507, 273, 27914, 1003, 27604, 243, 5605, 663, 1030, 1307, 1876, 27607, 2017, 48, 5672, 251, 25764, 13267, 27600, 459, 13856, 87, 11239, 2317, 2351, 4549, 772, 27599, 276, 8, 84, 6, 13799, 6, 37, 5361, 11842, 27607, 25754, 31, 27599, 589, 14313, 19, 10106, 81, 4636, 684, 5908, 26809, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 0\n",
      "label_mlm: [    0     0     0     0     0  3708 27600  3708 12972  5059 27841 27725\n",
      "  2429     0     0     0     0     0     0     0     0    46 27870 27600\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0  7559  3989   226     0     0     0     0     0     0     0     0\n",
      "     0     0 12835     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0    92     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "  9133     0 11444     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 라인 단위로 처리\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for i, line in enumerate(tqdm(f, total=total)):\n",
    "        if 5 < i:  # 테스트를 위해서 5개만 확인\n",
    "            break\n",
    "        data = json.loads(line)\n",
    "        # encoder token\n",
    "        enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "        enc_token += [0] * (n_seq - len(enc_token))\n",
    "        # segment\n",
    "        segment = data[\"segment\"]\n",
    "        segment += [0] * (n_seq - len(segment))\n",
    "        # nsp label\n",
    "        label_nsp = data[\"is_next\"]\n",
    "        # mlm label\n",
    "        mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "        mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "        label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "        label_mlm[mask_idx] = mask_label\n",
    "\n",
    "        print(data)\n",
    "        print(\"enc_token:\", enc_token)\n",
    "        print(\"segment:\", segment)\n",
    "        print(\"label_nsp:\", label_nsp)\n",
    "        print(\"label_mlm:\", label_mlm)\n",
    "        print()\n",
    "\n",
    "        assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "        enc_tokens[i] = enc_token\n",
    "        segments[i] = segment\n",
    "        labels_nsp[i] = label_nsp\n",
    "        labels_mlm[i] = label_mlm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-terrain",
   "metadata": {},
   "source": [
    "###  load_pre_train_data() : 학습에 필요한 데이터를 로딩하는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-trouble",
   "metadata": {},
   "source": [
    "**np.memmap**을 사용해 메모리 효율적으로 만들어진 데이터를 로딩하는 함수를 아래와 같이 구성하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "documented-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
    "    \"\"\"\n",
    "    학습에 필요한 데이터를 로드\n",
    "    :param vocab: vocab\n",
    "    :param filename: 전처리된 json 파일\n",
    "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
    "    :param count: 데이터 수 제한 (None이면 전체)\n",
    "    :return enc_tokens: encoder inputs\n",
    "    :return segments: segment inputs\n",
    "    :return labels_nsp: nsp labels\n",
    "    :return labels_mlm: mlm labels\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            # 데이터 수 제한\n",
    "            if count is not None and count <= total:\n",
    "                break\n",
    "    \n",
    "    # np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, total=total)):\n",
    "            if total <= i:\n",
    "                print(\"data load early stop\", total, i)\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            # encoder token\n",
    "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "            enc_token += [0] * (n_seq - len(enc_token))\n",
    "            # segment\n",
    "            segment = data[\"segment\"]\n",
    "            segment += [0] * (n_seq - len(segment))\n",
    "            # nsp label\n",
    "            label_nsp = data[\"is_next\"]\n",
    "            # mlm label\n",
    "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "            label_mlm[mask_idx] = mask_label\n",
    "\n",
    "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "            enc_tokens[i] = enc_token\n",
    "            segments[i] = segment\n",
    "            labels_nsp[i] = label_nsp\n",
    "            labels_mlm[i] = label_mlm\n",
    "\n",
    "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "major-simon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46371af23add4f189030037b6e6d34fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load early stop 128000 128000\n"
     ]
    }
   ],
   "source": [
    "# 128000 건만 메모리에 로딩\n",
    "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128, count=128000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "prime-island",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([    5,   103, 28313, 28290, 19041, 27718,    98, 27878, 15784,\n",
       "          2543,   309,   337,  5771, 27616, 27603,     6,     6,  3715,\n",
       "         27625,  5551,     6,     6,  2378,  5249,     6,     6,    13,\n",
       "         20590,  2386,  2163, 27596, 27671,   969,  8047,   173,   607,\n",
       "          2387,   317, 27604,  3926, 27625,     6,    37, 18995,  8198,\n",
       "          9858,  1447,  1921, 27625,  5551,     6,    18,   451,  4267,\n",
       "         27599,  4864,  6436,    25,  5551, 27646, 18205,   928,   157,\n",
       "         27821,    61, 27773,   530, 27604,  3372,   523,  3409,   673,\n",
       "          5551,    18,   982, 13264, 27599,     6,     6,     6,     6,\n",
       "             6,     6,  6945,  3554,  6719, 12788,  2046,  5890,  1853,\n",
       "         27599,     4, 16415,     6,  3324,  1042,   103, 27610, 27686,\n",
       "         27718, 25250,  7504,   416,     6,     6,   131, 27662,     7,\n",
       "         27629,   203,   241, 27602,  4867,     6,   243,  5898,   796,\n",
       "           663,  1647,  4630, 27625,   203,  3008, 27625, 27616,    16,\n",
       "         27599,     4], dtype=int32),\n",
       " memmap([    5,  2191, 27599,  5078,    81, 27604,   342,  4812, 27625,\n",
       "           294, 14456,     6, 24930,  2540, 27600,   488,  4871,  2524,\n",
       "         13358,   171, 27599,   330, 27604, 14456,     6,  4842, 27682,\n",
       "         27625,  2131, 14135,  9943,   761, 28254,   658,   171, 27599,\n",
       "            13,     6, 13069, 11312,   496,  8020,  1910, 27633,  4216,\n",
       "           664,   926,  5238,  1053,  5583, 27614,  2419,  2470, 27604,\n",
       "         21622, 27602,   838, 15403, 27760,   824,  3525, 13998,  7619,\n",
       "         27599,     4,   371, 27604,    29, 28018, 27793,  1326, 27787,\n",
       "            66,   412, 22289,    28, 27599,  1326,  5884,     6,  2573,\n",
       "            66,  1599, 27653,   639,  3883,   353, 27599, 17506,  5263,\n",
       "          1326,  5884,    19,   402,     6,     6,     6,     6,     6,\n",
       "          2742,    31, 27599,     6, 16343,     6,     6,     6,     6,\n",
       "             6,     6,     6,     6, 10603, 27616,     9, 25545,  1599,\n",
       "         27653,   639,   254,   238,   787,  2654,   784, 27604,  1925,\n",
       "           259,     4], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 0,\n",
       " 0,\n",
       " memmap([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,  4578, 27599,     0,\n",
       "             0,     0,    37, 11234,     0,     0,  9858,  3294,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,  5551,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,    37,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,  5551,  5053,   982,  4739,\n",
       "           151, 27604,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0, 25250,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,  5708, 27625,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,   788,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0], dtype=int32),\n",
       " memmap([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,    89,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0, 15170,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,  4031,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0, 11497,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,   231, 11497,  9933, 27607,  2042,\n",
       "             0,     0,     0, 11364,     0,  1911, 27604,    68, 27650,\n",
       "         27617,  3065, 28116, 27601,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0], dtype=int32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 처음과 마지막 확인\n",
    "pre_train_inputs[0][0], pre_train_inputs[0][-1], pre_train_inputs[1][0], pre_train_inputs[1][-1], pre_train_labels[0][0], pre_train_labels[0][-1], pre_train_labels[1][0], pre_train_labels[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-lindsay",
   "metadata": {},
   "source": [
    "## BERT 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-firewall",
   "metadata": {},
   "source": [
    "이제 본격적으로 BERT model을 구현해 보겠습니다.\n",
    "\n",
    "**BERT가 transformer encoder로 구현되어 있다는 것은 자명합니다.**\n",
    "\n",
    "이미 여러 번 다뤄 본 transformer의 모델 구조와 거의 유사하지만, 3개의 embedding 레이어를 가진다는 점에 유의해야 합니다."
   ]
  },
  {
   "attachments": {
    "003.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "third-continent",
   "metadata": {},
   "source": [
    "![003.PNG](attachment:003.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-trainer",
   "metadata": {},
   "source": [
    "우선, 몇 가지 유틸리티 함수에 대한 정의를 내리겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "occasional-grove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수가 성공적으로 구현되었다.\n"
     ]
    }
   ],
   "source": [
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask\n",
    "print(\"함수가 성공적으로 구현되었다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "light-fountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수가 성공적으로 구현되었다.\n"
     ]
    }
   ],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation 함수\n",
    "    :param x: 입력 값\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5 * x * (1 + K.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))\n",
    "print(\"함수가 성공적으로 구현되었다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "intensive-surprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수가 성공적으로 구현되었다.\n"
     ]
    }
   ],
   "source": [
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer 생성\n",
    "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer 생성\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer\n",
    "print(\"함수가 성공적으로 구현되었다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "heavy-franchise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config 클래스가 성공적으로 구현되었다.\n"
     ]
    }
   ],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        file에서 Config를 생성 함\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)\n",
    "print(\"Config 클래스가 성공적으로 구현되었다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-french",
   "metadata": {},
   "source": [
    "이제 본격적으로 embedding 레이어를 쌓아 나가겠습니다. 아래는 Token Embedding의 구현입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "nonprofit-commerce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SharedEmbedding 클래스가 정의되었다.\n"
     ]
    }
   ],
   "source": [
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighed Shaed Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight 생성\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :param mode: 실행 모드\n",
    "        :return: embedding or linear 실행 결과\n",
    "        \"\"\"\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear 실행\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs\n",
    "    \n",
    "print(\"SharedEmbedding 클래스가 정의되었다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-employee",
   "metadata": {},
   "source": [
    "Positional Embedding 레이어는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "seventh-toyota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PositionalEmbedding 클래스가 정의되었다.\n"
     ]
    }
   ],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Positional Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :return embed: positional embedding lookup 결과\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed\n",
    "    \n",
    "print(\"PositionalEmbedding 클래스가 정의되었다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-project",
   "metadata": {},
   "source": [
    "상대적으로 매우 간단한 Segment Embedding은 별도의 레이어를 구현하지 않고 BERT 클래스에서 간단히 포함하는 정도로만 하겠습니다.\n",
    "\n",
    "아래는 자주 보았던 **ScaleDotProductAttention**과 이를 활용한 **MultiHeadAttention**입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "figured-harvey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaleDotProductAttention 클래스가 정의되었다.\n"
     ]
    }
   ],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out\n",
    "    \n",
    "print(\"ScaleDotProductAttention 클래스가 정의되었다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "seeing-cancellation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiHeadAttention 클래스도 정의되었다.\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
    "        # transpose and liner\n",
    "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "\n",
    "        return attn_out\n",
    "    \n",
    "print(\"MultiHeadAttention 클래스도 정의되었다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-sender",
   "metadata": {},
   "source": [
    "이를 바탕으로 transformer encoder 레이어를 구성하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "photographic-bulletin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PositionWiseFeedForward 클래스가 정의되었다.\n"
     ]
    }
   ],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward 실행 결과\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val\n",
    "    \n",
    "print(\"PositionWiseFeedForward 클래스가 정의되었다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "given-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Layer 클래스가 정의되었다.\n"
     ]
    }
   ],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
    "        :param self_mask: enc_tokens의 pad mask\n",
    "        :return enc_out: EncoderLayer 실행 결과\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out\n",
    "    \n",
    "print(\"Encoder Layer 클래스가 정의되었다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-actor",
   "metadata": {},
   "source": [
    "최종적으로 구성할 BERT 레이어는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "brilliant-testament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여기까지 따라오느라 고생했어요~👍\n"
     ]
    }
   ],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionalEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: (enc_tokens, segments)\n",
    "        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
    "        \"\"\"\n",
    "        enc_tokens, segments = inputs\n",
    "\n",
    "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: 입력 tokens\n",
    "        :param segments: 입력 segments\n",
    "        :return embed: embedding 결과\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed\n",
    "    \n",
    "print(\"여기까지 따라오느라 고생했어요~👍\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-fiction",
   "metadata": {},
   "source": [
    "BERT 레이어를 바탕으로 최종적으로 만들어질 pretrain용 BERT 모델 구성은 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "explicit-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Layer class 정의\n",
    "class PooledOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    " \n",
    "    def call(self, inputs):\n",
    "        outputs = self.dense1(inputs)\n",
    "        outputs = self.dense2(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "biblical-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_pre_train(config):\n",
    "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
    "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
    "\n",
    "    bert = BERT(config)\n",
    "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
    "\n",
    "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
    "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
    "\n",
    "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-brunei",
   "metadata": {},
   "source": [
    "아주 작은 pretrain용 BERT 모델(test_model)을 생성하여 동작을 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "outstanding-coordination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 4,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 3,\n",
       " 'n_seq': 256,\n",
       " 'n_vocab': 32007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dominant-hollywood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2/2 [==============================] - 5s 32ms/step - loss: 11.1932 - nsp_loss: 0.7411 - mlm_loss: 10.4521 - nsp_acc: 0.6000 - mlm_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 10.0369 - nsp_loss: 0.6172 - mlm_loss: 9.4197 - nsp_acc: 0.8000 - mlm_acc: 0.0133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3720041cd0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seq = 10\n",
    "\n",
    "# make test inputs\n",
    "enc_tokens = np.random.randint(0, len(vocab), (10, n_seq))\n",
    "segments = np.random.randint(0, 2, (10, n_seq))\n",
    "labels_nsp = np.random.randint(0, 2, (10,))\n",
    "labels_mlm = np.random.randint(0, len(vocab), (10, n_seq))\n",
    "\n",
    "test_model = build_model_pre_train(config)\n",
    "test_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=[\"acc\"])\n",
    "\n",
    "# test model fit\n",
    "test_model.fit((enc_tokens, segments), (labels_nsp, labels_mlm), epochs=2, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-dutch",
   "metadata": {},
   "source": [
    "**test_model.fit()** 이 잘 구동되었음을 확인할 수 있었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-internet",
   "metadata": {},
   "source": [
    "## Pretrain 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-artist",
   "metadata": {},
   "source": [
    "**loss나 accuracy와 같이 기본적으로 필요한 계산 관련 함수**를 미리 정의해 두도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "starting-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    loss 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # loss 계산\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return loss * 20  # mlm을 더 잘 학습하도록 20배 증가 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "pharmaceutical-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    acc 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # 정답 여부 확인\n",
    "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
    "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
    "    matches *= mask\n",
    "    # 정확도 계산\n",
    "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-thought",
   "metadata": {},
   "source": [
    "한편, Learning Rate 스케줄링도 아래와 같이 구현합니다. WarmUp 이후 consine 형태로 감소하는 스케줄을 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "expired-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    CosineSchedule Class\n",
    "    \"\"\"\n",
    "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param train_steps: 학습 step 총 합\n",
    "        :param warmup_steps: warmup steps\n",
    "        :param max_lr: 최대 learning rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0 < warmup_steps < train_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.train_steps = train_steps\n",
    "        self.max_lr = max_lr\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        \"\"\"\n",
    "        learning rate 계산\n",
    "        :param step_num: 현재 step number\n",
    "        :retrun: 계산된 learning rate\n",
    "        \"\"\"\n",
    "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
    "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
    "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
    "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
    "        return (state * lr1 + (1 - state) * lr2) * self.max_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "remarkable-adaptation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute lr \n",
    "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
    "lrs = []\n",
    "for step_num in range(4000):\n",
    "    lrs.append(test_schedule(float(step_num)).numpy())\n",
    "\n",
    "# draw\n",
    "plt.plot(lrs, 'r-', label='learning_rate')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-subcommittee",
   "metadata": {},
   "source": [
    "이제 모델을 실제로 빌드해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "usual-lobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_tokens (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segments (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BERT)                     ((None, 256), (None, 10629632    enc_tokens[0][0]                 \n",
      "                                                                 segments[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooled_nsp (PooledOutput)       (None, 2)            66304       bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "nsp (Softmax)                   (None, 2)            0           pooled_nsp[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlm (Softmax)                   (None, None, 32007)  0           bert[0][1]                       \n",
      "==================================================================================================\n",
      "Total params: 10,695,936\n",
      "Trainable params: 10,695,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "pre_train_model = build_model_pre_train(config)\n",
    "pre_train_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-roberts",
   "metadata": {},
   "source": [
    "**🔥🔥🔥 이제 본격적으로 학습을 진행합니다. 🔥🔥🔥**\n",
    "\n",
    "1Epoch만 학습하는 데도 10분 이상의 상당한 시간이 소요될 것입니다. 그리고 메모리 오류가 날 수 있으니 배치 사이즈에도 유의해 주세요. 참고로 우리는 전체 데이터셋 중의 1/7 수준인 128000건만 로딩해서 사용 중이라는 것을 기억합시다.\n",
    "\n",
    "Optimize 함수로는 Adam을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "particular-keeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 20000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# optimizer\n",
    "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
    "print(\"train_steps:\", train_steps)\n",
    "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# compile\n",
    "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "abstract-parent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1134s 565ms/step - loss: 24.1836 - nsp_loss: 0.6661 - mlm_loss: 23.5175 - nsp_acc: 0.5711 - mlm_lm_acc: 0.0877\n",
      "\n",
      "Epoch 00001: mlm_lm_acc improved from -inf to 0.08809, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1136s 568ms/step - loss: 20.5749 - nsp_loss: 0.6193 - mlm_loss: 19.9557 - nsp_acc: 0.6336 - mlm_lm_acc: 0.1184\n",
      "\n",
      "Epoch 00002: mlm_lm_acc improved from 0.08809 to 0.12309, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1137s 569ms/step - loss: 19.2915 - nsp_loss: 0.5869 - mlm_loss: 18.7046 - nsp_acc: 0.6908 - mlm_lm_acc: 0.1366\n",
      "\n",
      "Epoch 00003: mlm_lm_acc improved from 0.12309 to 0.13884, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1138s 569ms/step - loss: 18.0205 - nsp_loss: 0.5573 - mlm_loss: 17.4633 - nsp_acc: 0.7333 - mlm_lm_acc: 0.1555\n",
      "\n",
      "Epoch 00004: mlm_lm_acc improved from 0.13884 to 0.16204, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1139s 570ms/step - loss: 16.1754 - nsp_loss: 0.5313 - mlm_loss: 15.6441 - nsp_acc: 0.7661 - mlm_lm_acc: 0.1881\n",
      "\n",
      "Epoch 00005: mlm_lm_acc improved from 0.16204 to 0.19200, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1140s 570ms/step - loss: 15.1414 - nsp_loss: 0.5010 - mlm_loss: 14.6405 - nsp_acc: 0.8040 - mlm_lm_acc: 0.2080\n",
      "\n",
      "Epoch 00006: mlm_lm_acc improved from 0.19200 to 0.20988, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1139s 569ms/step - loss: 14.5099 - nsp_loss: 0.4763 - mlm_loss: 14.0336 - nsp_acc: 0.8305 - mlm_lm_acc: 0.2215\n",
      "\n",
      "Epoch 00007: mlm_lm_acc improved from 0.20988 to 0.22253, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1139s 570ms/step - loss: 14.1261 - nsp_loss: 0.4598 - mlm_loss: 13.6663 - nsp_acc: 0.8495 - mlm_lm_acc: 0.2299\n",
      "\n",
      "Epoch 00008: mlm_lm_acc improved from 0.22253 to 0.23107, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1140s 570ms/step - loss: 13.8853 - nsp_loss: 0.4467 - mlm_loss: 13.4386 - nsp_acc: 0.8639 - mlm_lm_acc: 0.2365\n",
      "\n",
      "Epoch 00009: mlm_lm_acc improved from 0.23107 to 0.23655, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1140s 570ms/step - loss: 13.7652 - nsp_loss: 0.4405 - mlm_loss: 13.3247 - nsp_acc: 0.8699 - mlm_lm_acc: 0.2387\n",
      "\n",
      "Epoch 00010: mlm_lm_acc improved from 0.23655 to 0.23872, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n"
     ]
    }
   ],
   "source": [
    "# save weights callback\n",
    "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_dir}/bert_pre_train.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
    "# train\n",
    "history = pre_train_model.fit(pre_train_inputs, pre_train_labels, epochs=epochs, batch_size=batch_size, callbacks=[save_weights])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-paraguay",
   "metadata": {},
   "source": [
    "학습이 완료된 후, 시각화한 결과는 다음과 같았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "brown-webmaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 흐름 시각화\n",
    "plt.figure(figsize=(9, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['nsp_loss'], 'b-', label='nsp_loss')\n",
    "plt.plot(history.history['mlm_loss'], 'r--', label='mlm_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['nsp_acc'], 'g-', label='nsp_acc')\n",
    "plt.plot(history.history['mlm_lm_acc'], 'k--', label='mlm_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-native",
   "metadata": {},
   "source": [
    "## 결과 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-birth",
   "metadata": {},
   "source": [
    "**이번 프로젝트 결과를 다음과 같이 정리할 수 있습니다.**\n",
    "\n",
    "- pretrained된 모델로 10번의 Epoch를 진행하는 동안 loss는 안정적으로 감소한 반면 accuracy는 안정적으로 증가했습니다.\n",
    "- nsp_loss, nsp_acc는 Next Sentence Prediction을 수행하여 나타난 손실과 예측 정확도를 나타냅니다.\n",
    "- mlm_loss, mlm_acc는 Mask LM 부분에서 나타난 손실과 예측 정확도를 의미합니다.\n",
    "- 대략 5 epoch 정도에서 정확도가 80%를 넘겼으며 10회째에서는 거의 87% 정도를 기록했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-relief",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-affiliate",
   "metadata": {},
   "source": [
    "- 단어장의 크기(vocab_size)를 실습에서의 32000의 25% 수준인 8000으로 설정하여 진행했음에도 불구하고 전체 모델 학습에 소요된 시간이 1 epoch 당 약 10분으로 대략 2시간 가까이 소요되었습니다.\n",
    "- 단어장의 크기를 32000으로 돌리는 작업은 시간관계상 직접 하지 않고 넘어간 뒤 바로 8000개로 제한된 조건 하에서 프로젝트를 진행하여, 둘을 비교해 보지 못한 것은 아쉬웠습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
